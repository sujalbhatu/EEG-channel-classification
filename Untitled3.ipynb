{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/5GwlTI1vWRbKNkHJYbc5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujalbhatu/EEG-channel-classification/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGMlrsoARgmd",
        "outputId": "72c7f757-949a-4dca-825b-91bba3406cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDeps installed.\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install --quiet mne tqdm numpy scipy scikit-learn matplotlib torch torchvision\n",
        "print(\"Deps installed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive and unzip dataset into /content/bciciv2a\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# <-- EDIT THIS: path in your Drive to the zip you uploaded -->\n",
        "DRIVE_ZIP_PATH = '/content/drive/MyDrive/dataset/bciciv2a.zip'\n",
        "\n",
        "# target extraction folder (local VM)\n",
        "TARGET_DIR = '/content/bciciv2a'\n",
        "\n",
        "import os, sys\n",
        "print(\"Zip path:\", DRIVE_ZIP_PATH)\n",
        "print(\"Target dir:\", TARGET_DIR)\n",
        "\n",
        "# create target dir and unzip\n",
        "os.makedirs(TARGET_DIR, exist_ok=True)\n",
        "!unzip -q \"$DRIVE_ZIP_PATH\" -d \"$TARGET_DIR\" || echo \"unzip failed or zip not found\"\n",
        "\n",
        "# quick listing to confirm\n",
        "print(\"Listing files in target dir (first 200 chars):\")\n",
        "!ls -la \"$TARGET_DIR\" | sed -n '1,200p'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXjey3neRvoX",
        "outputId": "99de8a7b-5bec-45ab-9385-d73b8ef980c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Zip path: /content/drive/MyDrive/dataset/bciciv2a.zip\n",
            "Target dir: /content/bciciv2a\n",
            "Listing files in target dir (first 200 chars):\n",
            "total 12\n",
            "drwxr-xr-x   3 root root 4096 Oct  4 08:15 .\n",
            "drwxr-xr-x   1 root root 4096 Oct  4 08:15 ..\n",
            "drwxr-xr-x 111 root root 4096 Feb 20  2019 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "below one is not final\n"
      ],
      "metadata": {
        "id": "pd9hwbpFjICl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # ---------- BCICIV-2a 10-fold CV pipeline (EEG-ARNN) ----------\n",
        "# import os, argparse, math, time\n",
        "# from glob import glob\n",
        "# import numpy as np\n",
        "# import mne\n",
        "# from sklearn.model_selection import StratifiedKFold\n",
        "# from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, confusion_matrix\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from torch.utils.data import TensorDataset, DataLoader\n",
        "# import matplotlib.pyplot as plt\n",
        "# from tqdm import trange, tqdm\n",
        "\n",
        "# # ----------------------\n",
        "# # Helpers: preprocessing and epoch extraction\n",
        "# # ----------------------\n",
        "# def load_subject_gdfs(data_root, subject):\n",
        "#     s = f\"A{subject:02d}\"\n",
        "#     files = []\n",
        "#     fp_t = os.path.join(data_root, f\"{s}T.gdf\")\n",
        "#     if os.path.exists(fp_t):\n",
        "#         files.append(fp_t)\n",
        "#     fp_e = os.path.join(data_root, f\"{s}E.gdf\")\n",
        "#     if os.path.exists(fp_e):\n",
        "#         files.append(fp_e)\n",
        "#     if not files:\n",
        "#         raise FileNotFoundError(f\"No GDF files found for subject {subject} in {data_root}\")\n",
        "#     return files\n",
        "\n",
        "# def preprocess_and_epoch(gdf_file, l_freq=0.5, h_freq=50.0, sfreq=128.0, tmin=0.0, tmax=4.0, picks=None):\n",
        "#     raw = mne.io.read_raw_gdf(gdf_file, preload=True, verbose=False)\n",
        "#     if picks is None:\n",
        "#         picks = mne.pick_types(raw.info, eeg=True, exclude='bads')\n",
        "#     raw.filter(l_freq, h_freq, verbose=False)\n",
        "#     if abs(raw.info['sfreq'] - sfreq) > 1e-3:\n",
        "#         raw.resample(sfreq, npad='auto', verbose=False)\n",
        "#     events, event_id = mne.events_from_annotations(raw, verbose=False)\n",
        "#     chosen = []\n",
        "#     for ev in events:\n",
        "#         try:\n",
        "#             code = int(ev[2])\n",
        "#         except:\n",
        "#             continue\n",
        "#         if code in (769,770,771,772):\n",
        "#             chosen.append(ev)\n",
        "#     if not chosen:\n",
        "#         for ev in events:\n",
        "#             try:\n",
        "#                 code = int(ev[2])\n",
        "#                 if 769 <= code <= 772:\n",
        "#                     chosen.append(ev)\n",
        "#             except:\n",
        "#                 continue\n",
        "#     X = []; y = []\n",
        "#     n_chan = len(picks)\n",
        "#     nt = int((tmax - tmin) * sfreq)\n",
        "#     for ev in chosen:\n",
        "#         samp = int(ev[0])\n",
        "#         start = int(samp + tmin * sfreq)\n",
        "#         stop = int(samp + tmax * sfreq)\n",
        "#         if start < 0 or stop > raw.n_times:\n",
        "#             continue\n",
        "#         data = raw.get_data(picks=picks, start=start, stop=stop)\n",
        "#         if data.shape[1] != nt:\n",
        "#             if data.shape[1] > nt:\n",
        "#                 data = data[:, :nt]\n",
        "#             else:\n",
        "#                 pad = np.zeros((n_chan, nt - data.shape[1]))\n",
        "#                 data = np.hstack([data, pad])\n",
        "#         X.append(data)\n",
        "#         code = int(ev[2])\n",
        "#         lbl = {769:0, 770:1, 771:2, 772:3}.get(code, 0)\n",
        "#         y.append(lbl)\n",
        "#     if len(X) == 0:\n",
        "#         return np.zeros((0, n_chan, nt)), np.zeros((0,), dtype=int), [raw.ch_names[i] for i in picks]\n",
        "#     X = np.stack(X, axis=0)\n",
        "#     y = np.array(y, dtype=int)\n",
        "#     ch_names = [raw.ch_names[i] for i in picks]\n",
        "#     return X, y, ch_names\n",
        "\n",
        "# # ----------------------\n",
        "# # Model (TFEM + CARM)\n",
        "# # ----------------------\n",
        "# class TFEMBlock(nn.Module):\n",
        "#     def __init__(self, nch, F=16, k_t=16, pool=False, pool_k=4, drop=0.25):\n",
        "#         super().__init__()\n",
        "#         self.conv = nn.Conv2d(1, F, kernel_size=(1, k_t), padding=(0, k_t//2))\n",
        "#         self.bn = nn.BatchNorm2d(F)\n",
        "#         self.pw = nn.Conv2d(F, 1, kernel_size=1)\n",
        "#         self.pool = nn.AvgPool2d((1, pool_k)) if pool else None\n",
        "#         self.elu = nn.ELU()\n",
        "#         self.drop = nn.Dropout(drop)\n",
        "#     def forward(self, x):\n",
        "#         b, nch, t = x.shape\n",
        "#         x = x.unsqueeze(1)\n",
        "#         x = self.conv(x)\n",
        "#         x = self.bn(x)\n",
        "#         x = self.elu(x)\n",
        "#         x = self.pw(x)\n",
        "#         if self.pool:\n",
        "#             x = self.pool(x)\n",
        "#         x = self.drop(x)\n",
        "#         x = x.squeeze(1)\n",
        "#         return x\n",
        "\n",
        "# class CARM(nn.Module):\n",
        "#     def __init__(self, W_ref, tdim, drop=0.25):\n",
        "#         super().__init__()\n",
        "#         self.Wref = W_ref\n",
        "#         self.Theta = nn.Parameter(torch.randn(tdim, tdim) * 0.01)\n",
        "#         self.elu = nn.ELU()\n",
        "#         self.drop = nn.Dropout(drop)\n",
        "#     def forward(self, x):\n",
        "#         W = self.Wref\n",
        "#         h = torch.einsum('ij,bjf->bif', W, x)\n",
        "#         out = torch.einsum('bif,fg->big', h, self.Theta)\n",
        "#         out = self.elu(out)\n",
        "#         out = self.drop(out)\n",
        "#         return out\n",
        "\n",
        "# class EEG_ARNN(nn.Module):\n",
        "#     def __init__(self, nch, T0, ncls=4, F=16, pool_k=4, rho=0.001):\n",
        "#         super().__init__()\n",
        "#         self.nch = nch; self.T0 = T0; self.ncls = ncls; self.rho = rho\n",
        "#         W0 = torch.ones(nch, nch) - torch.eye(nch)\n",
        "#         Wt = W0 + torch.eye(nch)\n",
        "#         D = Wt.sum(dim=1)\n",
        "#         Dinv = torch.diag(1.0 / torch.sqrt(D + 1e-12))\n",
        "#         What0 = Dinv @ Wt @ Dinv\n",
        "#         self.W = nn.Parameter(What0.clone())\n",
        "#         self.tf1 = TFEMBlock(nch, F=F, k_t=16, pool=False)\n",
        "#         self.c1  = CARM(self.W, tdim=T0)\n",
        "#         self.tf2 = TFEMBlock(nch, F=F, k_t=16, pool=True, pool_k=pool_k)\n",
        "#         T2 = T0 // pool_k\n",
        "#         self.c2  = CARM(self.W, tdim=T2)\n",
        "#         self.tf3 = TFEMBlock(nch, F=F, k_t=16, pool=True, pool_k=pool_k)\n",
        "#         T3 = T2 // pool_k\n",
        "#         self.c3  = CARM(self.W, tdim=T3)\n",
        "#         self.fuse = nn.Conv2d(1, 16, kernel_size=(nch,1))\n",
        "#         self.bn_fuse = nn.BatchNorm2d(16)\n",
        "#         self.drop = nn.Dropout(0.25)\n",
        "#         self.elu = nn.ELU()\n",
        "#         self.fc = nn.Linear(16 * T3, ncls)\n",
        "#     def forward(self, x):\n",
        "#         x = self.tf1(x); x = self.c1(x)\n",
        "#         x = self.tf2(x); x = self.c2(x)\n",
        "#         x = self.tf3(x); x = self.c3(x)\n",
        "#         x = x.unsqueeze(1)\n",
        "#         x = self.fuse(x)\n",
        "#         x = self.bn_fuse(x)\n",
        "#         x = self.elu(x)\n",
        "#         x = self.drop(x)\n",
        "#         x = x.squeeze(2)\n",
        "#         b, oc, t = x.shape\n",
        "#         x = x.view(b, oc * t)\n",
        "#         out = self.fc(x)\n",
        "#         return out\n",
        "\n",
        "# # ----------------------\n",
        "# # Selection helpers (ES / AS)\n",
        "# # ----------------------\n",
        "# def edge_selection(W_tensor, topk_edges):\n",
        "#     Wn = W_tensor.detach().cpu().numpy()\n",
        "#     n = Wn.shape[0]\n",
        "#     delta = np.zeros((n,n))\n",
        "#     for i in range(n):\n",
        "#         for j in range(i+1, n):\n",
        "#             delta[i,j] = abs(Wn[i,j]) + abs(Wn[j,i])\n",
        "#             delta[j,i] = delta[i,j]\n",
        "#     upper = [(i,j,delta[i,j]) for i in range(n) for j in range(i+1,n)]\n",
        "#     upper_sorted = sorted(upper, key=lambda x: x[2], reverse=True)\n",
        "#     sel_edges = upper_sorted[:topk_edges]\n",
        "#     sel_nodes = sorted(list({i for e in sel_edges for i in (e[0], e[1])}))\n",
        "#     return sel_edges, sel_nodes\n",
        "\n",
        "# def aggregation_selection(W_tensor, topk_nodes):\n",
        "#     Wn = W_tensor.detach().cpu().numpy()\n",
        "#     n = Wn.shape[0]\n",
        "#     A = np.abs(Wn)\n",
        "#     deg = np.abs(Wn.sum(axis=1))\n",
        "#     tau = A.sum(axis=1) + deg\n",
        "#     idxs = np.argsort(-tau)\n",
        "#     sel_nodes = idxs[:topk_nodes].tolist()\n",
        "#     return sel_nodes, tau[idxs[:topk_nodes]]\n",
        "\n",
        "# # ----------------------\n",
        "# # Training & CV driver\n",
        "# # ----------------------\n",
        "# def train_epoch(model, loader, optimizer, device, crit, rho):\n",
        "#     model.train()\n",
        "#     total_loss = 0.0\n",
        "#     n = 0\n",
        "#     for xb, yb in loader:\n",
        "#         xb = xb.to(device); yb = yb.to(device)\n",
        "#         optimizer.zero_grad()\n",
        "#         out = model(xb)\n",
        "#         loss = crit(out, yb)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         with torch.no_grad():\n",
        "#             if model.W.grad is not None:\n",
        "#                 model.W.data = (1.0 - rho) * model.W.data - rho * model.W.grad.data\n",
        "#                 model.W.grad.zero_()\n",
        "#         total_loss += loss.item() * xb.size(0)\n",
        "#         n += xb.size(0)\n",
        "#     return total_loss / n\n",
        "\n",
        "# def eval_model(model, loader, device):\n",
        "#     model.eval()\n",
        "#     preds_all = []\n",
        "#     y_all = []\n",
        "#     with torch.no_grad():\n",
        "#         for xb, yb in loader:\n",
        "#             xb = xb.to(device); yb = yb.to(device)\n",
        "#             logits = model(xb)\n",
        "#             preds = logits.argmax(dim=1).cpu().numpy()\n",
        "#             preds_all.append(preds)\n",
        "#             y_all.append(yb.cpu().numpy())\n",
        "#     if len(preds_all) == 0:\n",
        "#         return np.array([]), np.array([])\n",
        "#     preds_all = np.concatenate(preds_all)\n",
        "#     y_all = np.concatenate(y_all)\n",
        "#     return preds_all, y_all\n",
        "\n",
        "# def run_10fold_subject(data_root, subject, epochs=200, batch=20, lr=1e-3, device='cuda'):\n",
        "#     files = load_subject_gdfs(data_root, subject)\n",
        "#     print(f\"Found files for subject {subject}: {files}\")\n",
        "#     Xs = []; ys = []\n",
        "#     ch_names = None\n",
        "#     for f in files:\n",
        "#         X, y, chs = preprocess_and_epoch(f, l_freq=0.5, h_freq=50.0, sfreq=128.0, tmin=0.0, tmax=4.0)\n",
        "#         if X.shape[0] == 0:\n",
        "#             continue\n",
        "#         if ch_names is None:\n",
        "#             ch_names = chs\n",
        "#         Xs.append(X); ys.append(y)\n",
        "#     if len(Xs) == 0:\n",
        "#         raise RuntimeError(\"No trials found after preprocessing.\")\n",
        "#     X = np.concatenate(Xs, axis=0)\n",
        "#     y = np.concatenate(ys, axis=0)\n",
        "#     print(\"Total trials:\", X.shape, \"Unique classes:\", np.unique(y))\n",
        "#     skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "#     fold = 0\n",
        "#     accs = []; baccs = []; f1s = []\n",
        "#     cm_total = np.zeros((4,4), dtype=int)\n",
        "#     device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
        "#     for train_idx, val_idx in skf.split(X, y):\n",
        "#         fold += 1\n",
        "#         print(f\"\\n=== Fold {fold}/10 ===\")\n",
        "#         Xtr, ytr = X[train_idx], y[train_idx]\n",
        "#         Xval, yval = X[val_idx], y[val_idx]\n",
        "#         Xtr_t = torch.tensor(Xtr, dtype=torch.float32)\n",
        "#         ytr_t = torch.tensor(ytr, dtype=torch.long)\n",
        "#         Xval_t = torch.tensor(Xval, dtype=torch.float32)\n",
        "#         yval_t = torch.tensor(yval, dtype=torch.long)\n",
        "#         tr_ds = torch.utils.data.TensorDataset(Xtr_t, ytr_t)\n",
        "#         val_ds = torch.utils.data.TensorDataset(Xval_t, yval_t)\n",
        "#         tr_loader = DataLoader(tr_ds, batch_size=batch, shuffle=True, drop_last=True)\n",
        "#         val_loader = DataLoader(val_ds, batch_size=batch, shuffle=False)\n",
        "#         nch = X.shape[1]; T0 = X.shape[2]; ncls = len(np.unique(y))\n",
        "#         model = EEG_ARNN(nch=nch, T0=T0, ncls=ncls).to(device)\n",
        "#         params = [p for n,p in model.named_parameters() if n != 'W' and p.requires_grad]\n",
        "#         opt = torch.optim.Adam(params, lr=lr)\n",
        "#         crit = nn.CrossEntropyLoss()\n",
        "#         for ep in range(1, epochs+1):\n",
        "#             loss = train_epoch(model, tr_loader, opt, device, crit, rho=model.rho)\n",
        "#             if ep % max(1, epochs//5) == 0 or ep==1:\n",
        "#                 print(f\"Epoch {ep}/{epochs} train_loss={loss:.4f}\")\n",
        "#         preds, ytrue = eval_model(model, val_loader, device)\n",
        "#         if preds.size == 0:\n",
        "#             print(\"No predictions for this fold (probably small val set). Skipping.\")\n",
        "#             continue\n",
        "#         acc = accuracy_score(ytrue, preds)\n",
        "#         bacc = balanced_accuracy_score(ytrue, preds)\n",
        "#         f1 = f1_score(ytrue, preds, average='macro')\n",
        "#         cm = confusion_matrix(ytrue, preds, labels=[0,1,2,3])\n",
        "#         cm_total += cm\n",
        "#         accs.append(acc); baccs.append(bacc); f1s.append(f1)\n",
        "#         print(f\"Fold {fold} acc={acc:.4f} bacc={bacc:.4f} f1_macro={f1:.4f}\")\n",
        "#         np.save(f\"W_subject{subject}_fold{fold}.npy\", model.W.detach().cpu().numpy())\n",
        "#     folds = list(range(1, len(accs)+1))\n",
        "#     plt.figure(figsize=(8,4))\n",
        "#     plt.plot(folds, accs, '-o', label='Acc')\n",
        "#     plt.plot(folds, baccs, '-s', label='BalAcc')\n",
        "#     plt.plot(folds, f1s, '-d', label='F1_macro')\n",
        "#     plt.xlabel('Fold'); plt.ylabel('Score'); plt.title(f\"Subject {subject} - 10-fold CV\")\n",
        "#     plt.legend(); plt.grid(True)\n",
        "#     plt.savefig(f\"subject{subject}_10fold_scores.png\", dpi=150)\n",
        "#     plt.close()\n",
        "#     plt.figure(figsize=(5,4))\n",
        "#     cm_norm = cm_total.astype(float) / (cm_total.sum(axis=1, keepdims=True) + 1e-12)\n",
        "#     plt.imshow(cm_norm, interpolation='nearest')\n",
        "#     plt.colorbar(); plt.title(f\"Subject {subject} - aggregated confusion matrix (normalized)\")\n",
        "#     plt.xlabel('Predicted'); plt.ylabel('True')\n",
        "#     ticks = [0,1,2,3]; plt.xticks(ticks); plt.yticks(ticks)\n",
        "#     for i in range(4):\n",
        "#         for j in range(4):\n",
        "#             plt.text(j, i, f\"{cm_total[i,j]}\", ha='center', va='center', color='w' if cm_norm[i,j]>0.5 else 'k')\n",
        "#     plt.savefig(f\"subject{subject}_confmat.png\", dpi=150)\n",
        "#     plt.close()\n",
        "#     print(\"\\n=== Summary ===\")\n",
        "#     print(\"Accs per fold:\", accs)\n",
        "#     print(\"Mean Acc:\", np.mean(accs), \"Std:\", np.std(accs))\n",
        "#     print(\"Mean BalAcc:\", np.mean(baccs), \"Mean F1_macro:\", np.mean(f1s))\n",
        "#     np.save(f\"subject{subject}_accs.npy\", np.array(accs))\n",
        "#     np.save(f\"subject{subject}_cm_total.npy\", cm_total)\n",
        "#     return {\"accs\":accs, \"baccs\":baccs, \"f1s\":f1s, \"cm_total\":cm_total, \"ch_names\":ch_names}\n",
        "\n",
        "# print(\"Pipeline code loaded. You can now call run_10fold_subject(DATA_ROOT, SUBJECT, ...).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISApupn7S8ga",
        "outputId": "8fa917aa-8e1e-45cb-cbc7-0610bef964fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline code loaded. You can now call run_10fold_subject(DATA_ROOT, SUBJECT, ...).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "its physionet data just folder name is bciciv2a"
      ],
      "metadata": {
        "id": "eihiFLUHjP8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "# ====== EDIT this to wherever your dataset parent folder is =====\n",
        "DATA_ROOT = '/content/bciciv2a/files'   # <- change to the folder that contains S001, S002, ...\n",
        "# =================================================================\n",
        "\n",
        "print(\"DATA_ROOT set to:\", DATA_ROOT)\n",
        "if not os.path.exists(DATA_ROOT):\n",
        "    print(\"WARNING: DATA_ROOT does not exist. If files are on Drive, mount Drive first or change path.\")\n",
        "else:\n",
        "    subs = sorted([d for d in os.listdir(DATA_ROOT) if d.upper().startswith('S')])\n",
        "    print(f\"Found {len(subs)} subject folders (showing first 20):\")\n",
        "    for s in subs[:20]:\n",
        "        p = os.path.join(DATA_ROOT, s)\n",
        "        # list some EDF files inside the subject folder\n",
        "        edfs = glob.glob(os.path.join(p, '*.edf'))\n",
        "        print(\" \", s, \" -> edf files:\", len(edfs), \"example:\", edfs[:3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmdBPAqOTD3J",
        "outputId": "51dcea52-723e-439d-be3b-439682af8048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA_ROOT set to: /content/bciciv2a/files\n",
            "Found 110 subject folders (showing first 20):\n",
            "  S001  -> edf files: 14 example: ['/content/bciciv2a/files/S001/S001R10.edf', '/content/bciciv2a/files/S001/S001R03.edf', '/content/bciciv2a/files/S001/S001R12.edf']\n",
            "  S002  -> edf files: 14 example: ['/content/bciciv2a/files/S002/S002R10.edf', '/content/bciciv2a/files/S002/S002R06.edf', '/content/bciciv2a/files/S002/S002R02.edf']\n",
            "  S003  -> edf files: 14 example: ['/content/bciciv2a/files/S003/S003R13.edf', '/content/bciciv2a/files/S003/S003R12.edf', '/content/bciciv2a/files/S003/S003R07.edf']\n",
            "  S004  -> edf files: 14 example: ['/content/bciciv2a/files/S004/S004R02.edf', '/content/bciciv2a/files/S004/S004R12.edf', '/content/bciciv2a/files/S004/S004R14.edf']\n",
            "  S005  -> edf files: 14 example: ['/content/bciciv2a/files/S005/S005R13.edf', '/content/bciciv2a/files/S005/S005R12.edf', '/content/bciciv2a/files/S005/S005R07.edf']\n",
            "  S006  -> edf files: 14 example: ['/content/bciciv2a/files/S006/S006R08.edf', '/content/bciciv2a/files/S006/S006R07.edf', '/content/bciciv2a/files/S006/S006R09.edf']\n",
            "  S007  -> edf files: 14 example: ['/content/bciciv2a/files/S007/S007R11.edf', '/content/bciciv2a/files/S007/S007R09.edf', '/content/bciciv2a/files/S007/S007R02.edf']\n",
            "  S008  -> edf files: 14 example: ['/content/bciciv2a/files/S008/S008R08.edf', '/content/bciciv2a/files/S008/S008R03.edf', '/content/bciciv2a/files/S008/S008R07.edf']\n",
            "  S009  -> edf files: 14 example: ['/content/bciciv2a/files/S009/S009R02.edf', '/content/bciciv2a/files/S009/S009R05.edf', '/content/bciciv2a/files/S009/S009R04.edf']\n",
            "  S010  -> edf files: 14 example: ['/content/bciciv2a/files/S010/S010R06.edf', '/content/bciciv2a/files/S010/S010R01.edf', '/content/bciciv2a/files/S010/S010R10.edf']\n",
            "  S011  -> edf files: 14 example: ['/content/bciciv2a/files/S011/S011R12.edf', '/content/bciciv2a/files/S011/S011R11.edf', '/content/bciciv2a/files/S011/S011R13.edf']\n",
            "  S012  -> edf files: 14 example: ['/content/bciciv2a/files/S012/S012R06.edf', '/content/bciciv2a/files/S012/S012R14.edf', '/content/bciciv2a/files/S012/S012R05.edf']\n",
            "  S013  -> edf files: 14 example: ['/content/bciciv2a/files/S013/S013R08.edf', '/content/bciciv2a/files/S013/S013R12.edf', '/content/bciciv2a/files/S013/S013R07.edf']\n",
            "  S014  -> edf files: 14 example: ['/content/bciciv2a/files/S014/S014R10.edf', '/content/bciciv2a/files/S014/S014R04.edf', '/content/bciciv2a/files/S014/S014R02.edf']\n",
            "  S015  -> edf files: 14 example: ['/content/bciciv2a/files/S015/S015R04.edf', '/content/bciciv2a/files/S015/S015R05.edf', '/content/bciciv2a/files/S015/S015R11.edf']\n",
            "  S016  -> edf files: 14 example: ['/content/bciciv2a/files/S016/S016R09.edf', '/content/bciciv2a/files/S016/S016R01.edf', '/content/bciciv2a/files/S016/S016R04.edf']\n",
            "  S017  -> edf files: 14 example: ['/content/bciciv2a/files/S017/S017R13.edf', '/content/bciciv2a/files/S017/S017R10.edf', '/content/bciciv2a/files/S017/S017R05.edf']\n",
            "  S018  -> edf files: 14 example: ['/content/bciciv2a/files/S018/S018R01.edf', '/content/bciciv2a/files/S018/S018R09.edf', '/content/bciciv2a/files/S018/S018R06.edf']\n",
            "  S019  -> edf files: 14 example: ['/content/bciciv2a/files/S019/S019R09.edf', '/content/bciciv2a/files/S019/S019R04.edf', '/content/bciciv2a/files/S019/S019R07.edf']\n",
            "  S020  -> edf files: 14 example: ['/content/bciciv2a/files/S020/S020R03.edf', '/content/bciciv2a/files/S020/S020R05.edf', '/content/bciciv2a/files/S020/S020R02.edf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PhysioNet loader + EEG-ARNN model (TFEM + CARM) + CV helper\n",
        "import os, glob, numpy as np\n",
        "import mne\n",
        "import torch, torch.nn as nn\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, confusion_matrix\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --------- epoch extraction for PhysioNet EDF format ----------\n",
        "def extract_physionet_subject(subject_folder, tmin=0.0, tmax=3.2, l_freq=0.5, h_freq=50.0, sfreq_target=160.0):\n",
        "    \"\"\"\n",
        "    subject_folder: path to folder 'S001', containing multiple .edf runs\n",
        "    returns: X (n_trials, n_chan, nt), y (n_trials,), ch_names\n",
        "    \"\"\"\n",
        "    edf_files = sorted(glob.glob(os.path.join(subject_folder, '*.edf')))\n",
        "    all_X = []; all_y = []; ch_names = None\n",
        "    nt = int((tmax - tmin) * sfreq_target)  # should be 512\n",
        "    for ef in edf_files:\n",
        "        raw = mne.io.read_raw_edf(ef, preload=True, verbose=False)\n",
        "        # filter + resample\n",
        "        raw.filter(l_freq, h_freq, verbose=False)\n",
        "        if abs(raw.info['sfreq'] - sfreq_target) > 1e-3:\n",
        "            raw.resample(sfreq_target, npad='auto', verbose=False)\n",
        "        picks = mne.pick_types(raw.info, eeg=True, exclude='bads')\n",
        "        # annotations -> events\n",
        "        try:\n",
        "            events, event_id = mne.events_from_annotations(raw, verbose=False)\n",
        "        except Exception:\n",
        "            events = []\n",
        "        # PhysioNet uses annotations; select events that indicate motor imagery/trials.\n",
        "        # We'll conservatively collect events and take windows after each annotation\n",
        "        for ev in events:\n",
        "            samp = int(ev[0])\n",
        "            start = int(samp + tmin * raw.info['sfreq'])\n",
        "            stop  = int(samp + tmax * raw.info['sfreq'])\n",
        "            if start < 0 or stop > raw.n_times:\n",
        "                continue\n",
        "            data = raw.get_data(picks=picks, start=start, stop=stop)\n",
        "            if data.shape[1] != nt:\n",
        "                if data.shape[1] > nt:\n",
        "                    data = data[:, :nt]\n",
        "                else:\n",
        "                    pad = np.zeros((len(picks), nt - data.shape[1]))\n",
        "                    data = np.hstack([data, pad])\n",
        "            # label: some PhysioNet files have annotation descriptions; here we create a binary label\n",
        "            # If you have specific annotation mapping you can adjust this mapping.\n",
        "            # For now: use annotation code parity to create 2 classes as a placeholder.\n",
        "            code = ev[2]\n",
        "            # map to integer label deterministically (example: even->0 odd->1)\n",
        "            lbl = 0 if (int(code) % 2 == 0) else 1\n",
        "            all_X.append(data); all_y.append(lbl)\n",
        "        if ch_names is None:\n",
        "            ch_names = [raw.ch_names[i] for i in picks]\n",
        "    if len(all_X) == 0:\n",
        "        return np.zeros((0, len(picks) if picks is not None else 0, nt)), np.zeros((0,), dtype=int), ch_names\n",
        "    X = np.stack(all_X, axis=0).astype(np.float32)\n",
        "    y = np.array(all_y, dtype=int)\n",
        "    return X, y, ch_names\n",
        "\n",
        "# ---------- Model (same EEG-ARNN design) ----------\n",
        "# Replace your TFEMBlock definition with this one (paste & run in the cell where you defined the model)\n",
        "# REPLACE your TFEMBlock with this (paste & run in the cell where you defined the model)\n",
        "class TFEMBlock(nn.Module):\n",
        "    def __init__(self, nch, F=16, k_t=15, pool=False, pool_k=4, drop=0.25):\n",
        "        super().__init__()\n",
        "        # use padding that preserves length for both odd and even k_t:\n",
        "        pad_t = (k_t - 1) // 2   # <-- fixed here (not k_t//2)\n",
        "        self.conv = nn.Conv2d(1, F, kernel_size=(1, k_t), padding=(0, pad_t))\n",
        "        self.bn = nn.BatchNorm2d(F)\n",
        "        self.pw = nn.Conv2d(F, 1, kernel_size=1)\n",
        "        self.pool = nn.AvgPool2d((1, pool_k)) if pool else None\n",
        "        self.elu = nn.ELU()\n",
        "        self.drop = nn.Dropout(drop)\n",
        "    def forward(self, x):\n",
        "        b, nch, t = x.shape\n",
        "        x = x.unsqueeze(1)           # (b,1,nch,t)\n",
        "        x = self.conv(x)             # (b,F,nch,t)\n",
        "        x = self.bn(x)\n",
        "        x = self.elu(x)\n",
        "        x = self.pw(x)               # (b,1,nch,t)\n",
        "        if self.pool:\n",
        "            x = self.pool(x)\n",
        "        x = self.drop(x)\n",
        "        x = x.squeeze(1)             # (b, nch, t')\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class CARM(nn.Module):\n",
        "    def __init__(self, Wref, tdim, drop=0.25):\n",
        "        super().__init__()\n",
        "        self.Wref = Wref\n",
        "        self.Theta = nn.Parameter(torch.randn(tdim, tdim) * 0.01)\n",
        "        self.elu = nn.ELU()\n",
        "        self.drop = nn.Dropout(drop)\n",
        "    def forward(self,x):\n",
        "\n",
        "        if self.Theta.shape[0] != x.shape[2]:\n",
        "          raise RuntimeError(f\"CARM tdim mismatch: Theta is {self.Theta.shape[0]} but input time dim is {x.shape[2]}\")\n",
        "        h = torch.einsum('ij,bjf->bif', self.Wref, x)\n",
        "        out = torch.einsum('bif,fg->big', h, self.Theta)\n",
        "        out = self.elu(out)\n",
        "        out = self.drop(out)\n",
        "        return out\n",
        "\n",
        "class EEG_ARNN(nn.Module):\n",
        "    def __init__(self, nch, T0, ncls=2, F=16, pool_k=4, rho=0.001):\n",
        "        super().__init__()\n",
        "        self.nch=nch; self.T0=T0; self.ncls=ncls; self.rho=rho\n",
        "\n",
        "        # Graph init\n",
        "        W0 = torch.ones(nch,nch) - torch.eye(nch)\n",
        "        Wt = W0 + torch.eye(nch)\n",
        "        D = Wt.sum(dim=1)\n",
        "        Dinv = torch.diag(1.0 / torch.sqrt(D + 1e-12))\n",
        "        What0 = Dinv @ Wt @ Dinv\n",
        "        self.W = nn.Parameter(What0.clone())\n",
        "\n",
        "        # ---- Temporal + Graph blocks (now using odd kernel size 15 to preserve time) ----\n",
        "        self.tf1 = TFEMBlock(nch, F=F, k_t=15, pool=False)\n",
        "        self.c1  = CARM(self.W, tdim=T0)\n",
        "\n",
        "        self.tf2 = TFEMBlock(nch, F=F, k_t=15, pool=True, pool_k=pool_k)\n",
        "        T2 = T0 // pool_k\n",
        "        self.c2  = CARM(self.W, tdim=T2)\n",
        "\n",
        "        self.tf3 = TFEMBlock(nch, F=F, k_t=15, pool=True, pool_k=pool_k)\n",
        "        T3 = T2 // pool_k\n",
        "        self.c3  = CARM(self.W, tdim=T3)\n",
        "\n",
        "        # ---- Fusion + Classifier ----\n",
        "        self.fuse = nn.Conv2d(1,16,kernel_size=(nch,1))\n",
        "        self.bn = nn.BatchNorm2d(16)\n",
        "        self.drop = nn.Dropout(0.25)\n",
        "        self.elu = nn.ELU()\n",
        "        self.fc = nn.Linear(16 * T3, ncls)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.tf1(x); x = self.c1(x)\n",
        "        x = self.tf2(x); x = self.c2(x)\n",
        "        x = self.tf3(x); x = self.c3(x)\n",
        "\n",
        "        x = x.unsqueeze(1)      # (b,1,nch,t)\n",
        "        x = self.fuse(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.elu(x)\n",
        "        x = self.drop(x)\n",
        "        x = x.squeeze(2)        # (b,16,t)\n",
        "\n",
        "        b,oc,t = x.shape\n",
        "        x = x.view(b, oc * t)\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "# ---------- tiny training / eval helpers ----------\n",
        "def train_epoch(model,loader,opt,device,crit,rho):\n",
        "    model.train(); total=0; n=0\n",
        "    for xb,yb in loader:\n",
        "        xb=xb.to(device); yb=yb.to(device)\n",
        "        opt.zero_grad()\n",
        "        out=model(xb); loss=crit(out,yb)\n",
        "        loss.backward(); opt.step()\n",
        "        with torch.no_grad():\n",
        "            if model.W.grad is not None:\n",
        "                model.W.data = (1.0 - rho) * model.W.data - rho * model.W.grad.data\n",
        "                model.W.grad.zero_()\n",
        "        total += loss.item() * xb.size(0); n += xb.size(0)\n",
        "    return total / max(1,n)\n",
        "\n",
        "def eval_model(model,loader,device):\n",
        "    model.eval(); preds=[]; ys=[]\n",
        "    with torch.no_grad():\n",
        "        for xb,yb in loader:\n",
        "            xb=xb.to(device); yb=yb.to(device)\n",
        "            out=model(xb)\n",
        "            preds.append(out.argmax(dim=1).cpu().numpy())\n",
        "            ys.append(yb.cpu().numpy())\n",
        "    if not preds: return np.array([]), np.array([])\n",
        "    return np.concatenate(preds), np.concatenate(ys)\n"
      ],
      "metadata": {
        "id": "qX3yqbrvV9KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick shape check (run after redefining TFEMBlock and model classes)\n",
        "import torch, torch.nn as nn\n",
        "nch = 64\n",
        "T0 = 512\n",
        "b = 2\n",
        "x = torch.randn(b, nch, T0)\n",
        "# init W param similar to model init\n",
        "W0 = torch.ones(nch, nch) - torch.eye(nch)\n",
        "Wt = W0 + torch.eye(nch)\n",
        "D = Wt.sum(dim=1); Dinv = torch.diag(1.0 / torch.sqrt(D + 1e-12)); What0 = Dinv @ Wt @ Dinv\n",
        "Wparam = nn.Parameter(What0.clone())\n",
        "tf = TFEMBlock(nch, F=16, k_t=15, pool=False)\n",
        "c = CARM(Wparam, tdim=T0)\n",
        "with torch.no_grad():\n",
        "    y1 = tf(x)\n",
        "    print(\"After TFEM time dim:\", y1.shape)    # expect (b, nch, 512)\n",
        "    y2 = c(y1)\n",
        "    print(\"After CARM time dim:\", y2.shape)    # expect (b, nch, 512)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csbmOeZkXo-s",
        "outputId": "6f631db0-774a-430a-e7a0-b5c9bdabc3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After TFEM time dim: torch.Size([2, 64, 512])\n",
            "After CARM time dim: torch.Size([2, 64, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = EEG_ARNN(nch=64, T0=512, ncls=2).to(device)\n",
        "xb = torch.randn(2, 64, 512).to(device)\n",
        "out = model(xb)   # should not raise einsum error\n",
        "print(out.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3FnV3hmfPp9",
        "outputId": "78fcffdf-9e6d-472a-bf5f-6715744a30c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======= EDIT ONLY THESE ======\n",
        "DATA_ROOT = '/content/bciciv2a/files'\n",
        "SUBJECT   = 'S001'\n",
        "# ==============================\n",
        "\n",
        "SUBJ_FOLDER = os.path.join(DATA_ROOT, SUBJECT)\n",
        "print(\"Using subject folder:\", SUBJ_FOLDER)\n",
        "assert os.path.exists(SUBJ_FOLDER), f\"Folder not found: {SUBJ_FOLDER}\"\n",
        "\n",
        "# Extract epochs\n",
        "X, y, chs = extract_physionet_subject(SUBJ_FOLDER, tmin=0.0, tmax=3.2,\n",
        "                                      l_freq=0.5, h_freq=50.0, sfreq_target=160.0)\n",
        "print(\"Extracted X shape:\", X.shape, \"y shape:\", y.shape, \"channels:\", len(chs))\n",
        "if X.shape[0] == 0:\n",
        "    raise RuntimeError(\"No epochs extracted. Check subject folder or annotation format.\")\n",
        "\n",
        "# Ensure float32\n",
        "X = X.astype(np.float32)\n",
        "\n",
        "# Optional: trim or pad time dimension to match model expectation (e.g., 512)\n",
        "TARGET_T = 512\n",
        "if X.shape[2] > TARGET_T:\n",
        "    X = X[:, :, :TARGET_T]\n",
        "elif X.shape[2] < TARGET_T:\n",
        "    pad_width = TARGET_T - X.shape[2]\n",
        "    X = np.pad(X, ((0,0),(0,0),(0,pad_width)), mode='constant')\n",
        "\n",
        "# Prepare 10-fold CV\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "fold = 0\n",
        "accs=[]; baccs=[]; f1s=[]\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "EPOCHS = 5   # quick test; set 200..500 for real\n",
        "BATCH = 16\n",
        "LR = 1e-3\n",
        "\n",
        "for train_idx, val_idx in skf.split(X,y):\n",
        "    fold += 1\n",
        "    print(f\"\\n--- Fold {fold} ---\")\n",
        "    Xtr, ytr = X[train_idx], y[train_idx]\n",
        "    Xval, yval = X[val_idx], y[val_idx]\n",
        "\n",
        "    # TensorDataset with float32 tensors\n",
        "    tr_ds = TensorDataset(torch.tensor(Xtr, dtype=torch.float32),\n",
        "                          torch.tensor(ytr))\n",
        "    val_ds = TensorDataset(torch.tensor(Xval, dtype=torch.float32),\n",
        "                           torch.tensor(yval))\n",
        "    tr_loader = DataLoader(tr_ds, batch_size=BATCH, shuffle=True, drop_last=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=BATCH, shuffle=False)\n",
        "\n",
        "    nch = X.shape[1]; T0 = X.shape[2]; ncls = len(np.unique(y))\n",
        "    model = EEG_ARNN(nch=nch, T0=T0, ncls=ncls).to(device)\n",
        "\n",
        "    params = [p for n,p in model.named_parameters() if n!='W' and p.requires_grad]\n",
        "    opt = torch.optim.Adam(params, lr=LR)\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "\n",
        "    for ep in range(1, EPOCHS+1):\n",
        "        loss = train_epoch(model, tr_loader, opt, device, crit, rho=model.rho)\n",
        "        if ep%max(1,EPOCHS//5)==0 or ep==1:\n",
        "            print(f\"Epoch {ep}/{EPOCHS} train_loss={loss:.4f}\")\n",
        "\n",
        "    preds, ytrue = eval_model(model, val_loader, device)\n",
        "    if preds.size==0:\n",
        "        print(\"No preds for fold; skipping\")\n",
        "        continue\n",
        "\n",
        "    acc = accuracy_score(ytrue, preds)\n",
        "    bacc = balanced_accuracy_score(ytrue, preds)\n",
        "    f1 = f1_score(ytrue, preds, average='macro')\n",
        "    accs.append(acc); baccs.append(bacc); f1s.append(f1)\n",
        "    print(f\"Fold {fold} -> acc {acc:.4f}, balacc {bacc:.4f}, f1 {f1:.4f}\")\n",
        "\n",
        "print(\"\\n=== Summary ===\")\n",
        "print(\"Mean acc:\", np.mean(accs), \"std acc:\", np.std(accs))\n",
        "print(\"Mean balacc:\", np.mean(baccs), \"mean f1:\", np.mean(f1s))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jlgK5RiWO5K",
        "outputId": "4bf72f23-3dc1-43d4-8119-4fa3afc6b707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using subject folder: /content/bciciv2a/files/S001\n",
            "Extracted X shape: (362, 64, 512) y shape: (362,) channels: 64\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch 1/5 train_loss=0.6353\n",
            "Epoch 2/5 train_loss=0.5984\n",
            "Epoch 3/5 train_loss=0.6022\n",
            "Epoch 4/5 train_loss=0.6099\n",
            "Epoch 5/5 train_loss=0.5911\n",
            "Fold 1 -> acc 0.7568, balacc 0.5000, f1 0.4308\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 1/5 train_loss=0.6176\n",
            "Epoch 2/5 train_loss=0.6031\n",
            "Epoch 3/5 train_loss=0.6157\n",
            "Epoch 4/5 train_loss=0.5548\n",
            "Epoch 5/5 train_loss=0.5895\n",
            "Fold 2 -> acc 0.7568, balacc 0.5000, f1 0.4308\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 1/5 train_loss=0.6063\n",
            "Epoch 2/5 train_loss=0.5913\n",
            "Epoch 3/5 train_loss=0.6350\n",
            "Epoch 4/5 train_loss=0.5990\n",
            "Epoch 5/5 train_loss=0.5855\n",
            "Fold 3 -> acc 0.7500, balacc 0.5000, f1 0.4286\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch 1/5 train_loss=0.6106\n",
            "Epoch 2/5 train_loss=0.6178\n",
            "Epoch 3/5 train_loss=0.5886\n",
            "Epoch 4/5 train_loss=0.6042\n",
            "Epoch 5/5 train_loss=0.6085\n",
            "Fold 4 -> acc 0.7500, balacc 0.5000, f1 0.4286\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch 1/5 train_loss=0.6321\n",
            "Epoch 2/5 train_loss=0.6015\n",
            "Epoch 3/5 train_loss=0.5922\n",
            "Epoch 4/5 train_loss=0.5755\n",
            "Epoch 5/5 train_loss=0.5771\n",
            "Fold 5 -> acc 0.7500, balacc 0.5000, f1 0.4286\n",
            "\n",
            "--- Fold 6 ---\n",
            "Epoch 1/5 train_loss=0.6246\n",
            "Epoch 2/5 train_loss=0.6257\n",
            "Epoch 3/5 train_loss=0.6189\n",
            "Epoch 4/5 train_loss=0.5741\n",
            "Epoch 5/5 train_loss=0.5990\n",
            "Fold 6 -> acc 0.7500, balacc 0.5000, f1 0.4286\n",
            "\n",
            "--- Fold 7 ---\n",
            "Epoch 1/5 train_loss=0.6544\n",
            "Epoch 2/5 train_loss=0.5864\n",
            "Epoch 3/5 train_loss=0.5805\n",
            "Epoch 4/5 train_loss=0.5902\n",
            "Epoch 5/5 train_loss=0.5623\n",
            "Fold 7 -> acc 0.7500, balacc 0.5000, f1 0.4286\n",
            "\n",
            "--- Fold 8 ---\n",
            "Epoch 1/5 train_loss=0.6089\n",
            "Epoch 2/5 train_loss=0.6237\n",
            "Epoch 3/5 train_loss=0.5745\n",
            "Epoch 4/5 train_loss=0.5965\n",
            "Epoch 5/5 train_loss=0.6180\n",
            "Fold 8 -> acc 0.7500, balacc 0.5000, f1 0.4286\n",
            "\n",
            "--- Fold 9 ---\n",
            "Epoch 1/5 train_loss=0.6306\n",
            "Epoch 2/5 train_loss=0.6070\n",
            "Epoch 3/5 train_loss=0.5940\n",
            "Epoch 4/5 train_loss=0.6033\n",
            "Epoch 5/5 train_loss=0.5689\n",
            "Fold 9 -> acc 0.7500, balacc 0.5000, f1 0.4286\n",
            "\n",
            "--- Fold 10 ---\n",
            "Epoch 1/5 train_loss=0.6113\n",
            "Epoch 2/5 train_loss=0.6018\n",
            "Epoch 3/5 train_loss=0.6432\n",
            "Epoch 4/5 train_loss=0.6171\n",
            "Epoch 5/5 train_loss=0.5901\n",
            "Fold 10 -> acc 0.7500, balacc 0.5000, f1 0.4286\n",
            "\n",
            "=== Summary ===\n",
            "Mean acc: 0.7513513513513514 std acc: 0.0027027027027027193\n",
            "Mean balacc: 0.5 mean f1: 0.429010989010989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======= EDIT ONLY THESE ======\n",
        "DATA_ROOT = '/content/bciciv2a/files'\n",
        "SUBJECT   = 'S001'\n",
        "# ==============================\n",
        "\n",
        "SUBJ_FOLDER = os.path.join(DATA_ROOT, SUBJECT)\n",
        "print(\"Using subject folder:\", SUBJ_FOLDER)\n",
        "assert os.path.exists(SUBJ_FOLDER), f\"Folder not found: {SUBJ_FOLDER}\"\n",
        "\n",
        "# Extract epochs\n",
        "X, y, chs = extract_physionet_subject(SUBJ_FOLDER, tmin=0.0, tmax=3.2,\n",
        "                                      l_freq=0.5, h_freq=50.0, sfreq_target=160.0)\n",
        "print(\"Extracted X shape:\", X.shape, \"y shape:\", y.shape, \"channels:\", len(chs))\n",
        "if X.shape[0] == 0:\n",
        "    raise RuntimeError(\"No epochs extracted. Check subject folder or annotation format.\")\n",
        "\n",
        "# Ensure float32\n",
        "X = X.astype(np.float32)\n",
        "\n",
        "# Optional: trim or pad time dimension to match model expectation (e.g., 512)\n",
        "TARGET_T = 512\n",
        "if X.shape[2] > TARGET_T:\n",
        "    X = X[:, :, :TARGET_T]\n",
        "elif X.shape[2] < TARGET_T:\n",
        "    pad_width = TARGET_T - X.shape[2]\n",
        "    X = np.pad(X, ((0,0),(0,0),(0,pad_width)), mode='constant')\n",
        "\n",
        "# Prepare 10-fold CV\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "fold = 0\n",
        "accs=[]; baccs=[]; f1s=[]\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "EPOCHS = 50   # quick test; set 200..500 for real\n",
        "BATCH = 16\n",
        "LR = 1e-3\n",
        "\n",
        "for train_idx, val_idx in skf.split(X,y):\n",
        "    fold += 1\n",
        "    print(f\"\\n--- Fold {fold} ---\")\n",
        "    Xtr, ytr = X[train_idx], y[train_idx]\n",
        "    Xval, yval = X[val_idx], y[val_idx]\n",
        "\n",
        "    # TensorDataset with float32 tensors\n",
        "    tr_ds = TensorDataset(torch.tensor(Xtr, dtype=torch.float32),\n",
        "                          torch.tensor(ytr))\n",
        "    val_ds = TensorDataset(torch.tensor(Xval, dtype=torch.float32),\n",
        "                           torch.tensor(yval))\n",
        "    tr_loader = DataLoader(tr_ds, batch_size=BATCH, shuffle=True, drop_last=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=BATCH, shuffle=False)\n",
        "\n",
        "    nch = X.shape[1]; T0 = X.shape[2]; ncls = len(np.unique(y))\n",
        "    model = EEG_ARNN(nch=nch, T0=T0, ncls=ncls).to(device)\n",
        "\n",
        "    params = [p for n,p in model.named_parameters() if n!='W' and p.requires_grad]\n",
        "    opt = torch.optim.Adam(params, lr=LR)\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "\n",
        "    for ep in range(1, EPOCHS+1):\n",
        "        loss = train_epoch(model, tr_loader, opt, device, crit, rho=model.rho)\n",
        "        if ep%max(1,EPOCHS//5)==0 or ep==1:\n",
        "            print(f\"Epoch {ep}/{EPOCHS} train_loss={loss:.4f}\")\n",
        "\n",
        "    preds, ytrue = eval_model(model, val_loader, device)\n",
        "    if preds.size==0:\n",
        "        print(\"No preds for fold; skipping\")\n",
        "        continue\n",
        "\n",
        "    acc = accuracy_score(ytrue, preds)\n",
        "    bacc = balanced_accuracy_score(ytrue, preds)\n",
        "    f1 = f1_score(ytrue, preds, average='macro')\n",
        "    accs.append(acc); baccs.append(bacc); f1s.append(f1)\n",
        "    print(f\"Fold {fold} -> acc {acc:.4f}, balacc {bacc:.4f}, f1 {f1:.4f}\")\n",
        "\n",
        "print(\"\\n=== Summary ===\")\n",
        "print(\"Mean acc:\", np.mean(accs), \"std acc:\", np.std(accs))\n",
        "print(\"Mean balacc:\", np.mean(baccs), \"mean f1:\", np.mean(f1s))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "8-Lx7adclliN",
        "outputId": "7bf575ff-ec87-4ee9-d3f7-cbafada8d137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using subject folder: /content/bciciv2a/files/S001\n",
            "Extracted X shape: (362, 64, 512) y shape: (362,) channels: 64\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch 1/50 train_loss=0.6034\n",
            "Epoch 10/50 train_loss=0.4364\n",
            "Epoch 20/50 train_loss=0.0120\n",
            "Epoch 30/50 train_loss=0.0006\n",
            "Epoch 40/50 train_loss=0.0003\n",
            "Epoch 50/50 train_loss=0.0002\n",
            "Fold 1 -> acc 0.6216, balacc 0.5238, f1 0.5204\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 1/50 train_loss=0.5964\n",
            "Epoch 10/50 train_loss=0.5110\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1794827987.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {ep}/{EPOCHS} train_loss={loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1636334326.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, opt, device, crit, rho)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, gc, pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
        "\n",
        "# ======= EDIT ONLY THESE ======\n",
        "DATA_ROOT = '/content/bciciv2a/files'\n",
        "SUBJECTS = [f\"S{str(i).zfill(3)}\" for i in range(1, 110)]  # S001 ... S109\n",
        "EPOCHS = 50      # max epochs, training will stop earlier if overfitting\n",
        "BATCH = 16\n",
        "LR = 1e-3\n",
        "TARGET_T = 512\n",
        "PATIENCE = 5     # early stopping patience in epochs\n",
        "# ==============================\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "all_accs, all_baccs, all_f1s = [], [], []\n",
        "\n",
        "for subj in SUBJECTS:\n",
        "    print(f\"\\n=== Processing {subj} ===\")\n",
        "    SUBJ_FOLDER = os.path.join(DATA_ROOT, subj)\n",
        "    if not os.path.exists(SUBJ_FOLDER):\n",
        "        print(f\"Folder not found: {SUBJ_FOLDER}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Extract epochs\n",
        "    X, y, chs = extract_physionet_subject(SUBJ_FOLDER, tmin=0.0, tmax=3.2,\n",
        "                                          l_freq=0.5, h_freq=50.0, sfreq_target=160.0)\n",
        "    if X.shape[0] == 0:\n",
        "        print(f\"No data for {subj}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    X = X.astype(np.float32)\n",
        "    if X.shape[2] > TARGET_T:\n",
        "        X = X[:, :, :TARGET_T]\n",
        "    elif X.shape[2] < TARGET_T:\n",
        "        pad_width = TARGET_T - X.shape[2]\n",
        "        X = np.pad(X, ((0,0),(0,0),(0,pad_width)), mode='constant')\n",
        "\n",
        "    # 10-fold CV per subject\n",
        "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    fold_accs, fold_baccs, fold_f1s = [], [], []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), start=1):\n",
        "        Xtr, ytr = X[train_idx], y[train_idx]\n",
        "        Xval, yval = X[val_idx], y[val_idx]\n",
        "\n",
        "        tr_ds = TensorDataset(torch.tensor(Xtr, dtype=torch.float32),\n",
        "                              torch.tensor(ytr))\n",
        "        val_ds = TensorDataset(torch.tensor(Xval, dtype=torch.float32),\n",
        "                               torch.tensor(yval))\n",
        "        tr_loader = DataLoader(tr_ds, batch_size=BATCH, shuffle=True, drop_last=True)\n",
        "        val_loader = DataLoader(val_ds, batch_size=BATCH, shuffle=False)\n",
        "\n",
        "        nch = X.shape[1]; T0 = X.shape[2]; ncls = len(np.unique(y))\n",
        "        model = EEG_ARNN(nch=nch, T0=T0, ncls=ncls).to(device)\n",
        "        params = [p for n,p in model.named_parameters() if n!='W' and p.requires_grad]\n",
        "        opt = torch.optim.Adam(params, lr=LR)\n",
        "        crit = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        best_val_acc = 0\n",
        "        counter = 0\n",
        "\n",
        "        for ep in range(1, EPOCHS+1):\n",
        "            train_loss = train_epoch(model, tr_loader, opt, device, crit, rho=model.rho)\n",
        "            preds, ytrue = eval_model(model, val_loader, device)\n",
        "            val_acc = accuracy_score(ytrue, preds)\n",
        "\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                counter = 0\n",
        "                # optionally save model checkpoint here\n",
        "            else:\n",
        "                counter += 1\n",
        "\n",
        "            if counter >= PATIENCE:\n",
        "                print(f\"Early stopping at epoch {ep} for fold {fold}\")\n",
        "                break\n",
        "\n",
        "        # Final evaluation for this fold\n",
        "        preds, ytrue = eval_model(model, val_loader, device)\n",
        "        fold_accs.append(accuracy_score(ytrue, preds))\n",
        "        fold_baccs.append(balanced_accuracy_score(ytrue, preds))\n",
        "        fold_f1s.append(f1_score(ytrue, preds, average='macro'))\n",
        "\n",
        "        # Free GPU memory for next fold\n",
        "        del model, tr_loader, val_loader, Xtr, Xval, ytr, yval\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    # Aggregate results for this subject\n",
        "    subj_acc = np.mean(fold_accs)\n",
        "    subj_bacc = np.mean(fold_baccs)\n",
        "    subj_f1 = np.mean(fold_f1s)\n",
        "    print(f\"{subj} -> acc {subj_acc:.4f}, balacc {subj_bacc:.4f}, f1 {subj_f1:.4f}\")\n",
        "\n",
        "    all_accs.append(subj_acc)\n",
        "    all_baccs.append(subj_bacc)\n",
        "    all_f1s.append(subj_f1)\n",
        "\n",
        "    # Save intermediate results\n",
        "    with open(\"subject_metrics.pkl\", \"wb\") as f:\n",
        "        pickle.dump({'accs': all_accs, 'baccs': all_baccs, 'f1s': all_f1s}, f)\n",
        "\n",
        "# Overall summary\n",
        "print(\"\\n=== Overall Summary Across Subjects ===\")\n",
        "print(\"Mean acc:\", np.mean(all_accs), \"std acc:\", np.std(all_accs))\n",
        "print(\"Mean balacc:\", np.mean(all_baccs), \"mean f1:\", np.mean(all_f1s))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "qTmTuvCmqwez",
        "outputId": "16214e18-29b5-4617-bccc-2f572877832b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing S001 ===\n",
            "Early stopping at epoch 6 for fold 1\n",
            "Early stopping at epoch 6 for fold 2\n",
            "Early stopping at epoch 6 for fold 3\n",
            "Early stopping at epoch 6 for fold 4\n",
            "Early stopping at epoch 6 for fold 5\n",
            "Early stopping at epoch 7 for fold 6\n",
            "Early stopping at epoch 6 for fold 7\n",
            "Early stopping at epoch 6 for fold 8\n",
            "Early stopping at epoch 11 for fold 9\n",
            "Early stopping at epoch 7 for fold 10\n",
            "S001 -> acc 0.6278, balacc 0.5111, f1 0.3916\n",
            "\n",
            "=== Processing S002 ===\n",
            "Early stopping at epoch 6 for fold 1\n",
            "Early stopping at epoch 6 for fold 2\n",
            "Early stopping at epoch 6 for fold 3\n",
            "Early stopping at epoch 6 for fold 4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3807893668.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1636334326.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, opt, device, crit, rho)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# -------------------------------\n",
        "# Step 0: Assume you have:\n",
        "# X -> shape (trials, channels, time)\n",
        "# y -> shape (trials,)\n",
        "# trained_model -> your EEG-ARNN model\n",
        "# -------------------------------\n",
        "\n",
        "# -------------------------------\n",
        "# Step 1: Aggregation Selection (AS) to pick top-k channels\n",
        "# -------------------------------\n",
        "def select_topk_channels_AS(adj_matrix, k):\n",
        "    \"\"\"\n",
        "    Select top-k channels using Aggregation Selection (AS)\n",
        "\n",
        "    Parameters:\n",
        "        adj_matrix: torch.Tensor, shape (C, C)\n",
        "            Learned adjacency matrix W* from CARM\n",
        "        k: int\n",
        "            Number of channels to select\n",
        "\n",
        "    Returns:\n",
        "        topk_indices: list of int\n",
        "            Indices of top-k channels\n",
        "    \"\"\"\n",
        "    # Total influence of each node = sum of abs(edge weights) + self-degree\n",
        "    node_scores = torch.sum(torch.abs(adj_matrix), dim=1) + torch.diag(adj_matrix)\n",
        "\n",
        "    # Get top-k node indices\n",
        "    topk_indices = torch.topk(node_scores, k=k).indices.tolist()\n",
        "    return topk_indices\n",
        "\n",
        "# Example usage:\n",
        "k = 20  # top 20 channels\n",
        "W_star = trained_model.CARM.W_hat  # assuming trained_model stores final W* in W_hat\n",
        "topk_channels = select_topk_channels_AS(W_star, k)\n",
        "print(\"Top-k channels selected:\", topk_channels)\n",
        "\n",
        "# -------------------------------\n",
        "# Step 2: Prepare dataset with top-k channels\n",
        "# -------------------------------\n",
        "X_topk = X[:, topk_channels, :]  # select only top-k channels\n",
        "dataset = TensorDataset(torch.tensor(X_topk, dtype=torch.float32),\n",
        "                        torch.tensor(y, dtype=torch.long))\n",
        "\n",
        "batch_size = 20\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# -------------------------------\n",
        "# Step 3: Define EEG-ARNN variant for top-k channels\n",
        "# -------------------------------\n",
        "class EEG_ARNN_TopK(nn.Module):\n",
        "    def __init__(self, num_channels, num_timepoints, num_classes=2):\n",
        "        super().__init__()\n",
        "        # --- TFEM example: simple temporal CNN ---\n",
        "        self.tfem = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=(1,16), stride=(1,1)),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "        # --- CARM placeholder for graph conv ---\n",
        "        self.num_channels = num_channels\n",
        "        self.graph_theta = nn.Parameter(torch.randn(num_channels, num_channels))\n",
        "        # --- Fully connected layer ---\n",
        "        self.fc = nn.Linear(num_channels * num_timepoints, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, channels, time)\n",
        "        x = x.unsqueeze(1)  # (batch, 1, channels, time) for Conv2d\n",
        "        x = self.tfem(x)    # (batch, 16, channels, time_out)\n",
        "        # Flatten for FC\n",
        "        x = x.flatten(start_dim=1)\n",
        "        out = self.fc(x)\n",
        "        return out\n",
        "\n",
        "# -------------------------------\n",
        "# Step 4: Train & evaluate top-k model\n",
        "# -------------------------------\n",
        "def train_evaluate(model, dataloader, epochs=5, lr=0.001):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Train loop\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for xb, yb in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs} -> train_loss={total_loss/len(dataloader):.4f}\")\n",
        "\n",
        "    # Evaluate accuracy\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in dataloader:\n",
        "            out = model(xb)\n",
        "            preds = torch.argmax(out, dim=1)\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "    acc = correct / total\n",
        "    print(f\"Accuracy on top-{k} channels: {acc*100:.2f}%\")\n",
        "    return acc\n",
        "\n",
        "# Initialize and train model\n",
        "num_timepoints = X_topk.shape[2]\n",
        "topk_model = EEG_ARNN_TopK(num_channels=k, num_timepoints=num_timepoints)\n",
        "topk_acc = train_evaluate(topk_model, dataloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "IK8GSKGCyNX-",
        "outputId": "cd761ec1-9550-4b77-d5be-c9d31aa0d660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trained_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1669538584.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m  \u001b[0;31m# top 20 channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mW_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCARM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_hat\u001b[0m  \u001b[0;31m# assuming trained_model stores final W* in W_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mtopk_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_topk_channels_AS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Top-k channels selected:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trained_model' is not defined"
          ]
        }
      ]
    }
  ]
}