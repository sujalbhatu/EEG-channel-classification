{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujalbhatu/EEG-channel-classification/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install --quiet mne tqdm numpy scipy scikit-learn matplotlib torch torchvision\n",
        "print(\"Deps installed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xU0hGlEf3hxy",
        "outputId": "a4346ef3-0467-49f6-fc61-02262cf26bcf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDeps installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive and unzip dataset into /content/bciciv2a\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# <-- EDIT THIS: path in your Drive to the zip you uploaded -->\n",
        "DRIVE_ZIP_PATH = '/content/drive/MyDrive/dataset/bciciv2a.zip'\n",
        "\n",
        "# target extraction folder (local VM)\n",
        "TARGET_DIR = '/content/bciciv2a'\n",
        "\n",
        "import os, sys\n",
        "print(\"Zip path:\", DRIVE_ZIP_PATH)\n",
        "print(\"Target dir:\", TARGET_DIR)\n",
        "\n",
        "# create target dir and unzip\n",
        "os.makedirs(TARGET_DIR, exist_ok=True)\n",
        "!unzip -q \"$DRIVE_ZIP_PATH\" -d \"$TARGET_DIR\" || echo \"unzip failed or zip not found\"\n",
        "\n",
        "# quick listing to confirm\n",
        "print(\"Listing files in target dir (first 200 chars):\")\n",
        "!ls -la \"$TARGET_DIR\" | sed -n '1,200p'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jWrk-lZ4LiU",
        "outputId": "3a747616-a7bb-4139-9809-d1520b3fd543"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Zip path: /content/drive/MyDrive/dataset/bciciv2a.zip\n",
            "Target dir: /content/bciciv2a\n",
            "Listing files in target dir (first 200 chars):\n",
            "total 12\n",
            "drwxr-xr-x   3 root root 4096 Oct  4 11:00 .\n",
            "drwxr-xr-x   1 root root 4096 Oct  4 11:00 ..\n",
            "drwxr-xr-x 111 root root 4096 Feb 20  2019 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------- Imports -----------------------------\n",
        "import os, glob, numpy as np\n",
        "import mne\n",
        "import torch, torch.nn as nn\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# ----------------------------- PhysioNet Loader -----------------------------\n",
        "def extract_physionet_subject(subject_folder, tmin=0.0, tmax=3.2, l_freq=0.5, h_freq=50.0, sfreq_target=160.0):\n",
        "    edf_files = sorted(glob.glob(os.path.join(subject_folder, '*.edf')))\n",
        "    all_X, all_y, ch_names = [], [], None\n",
        "    nt = int((tmax - tmin) * sfreq_target)\n",
        "    for ef in edf_files:\n",
        "        raw = mne.io.read_raw_edf(ef, preload=True, verbose=False)\n",
        "        raw.filter(l_freq, h_freq, verbose=False)\n",
        "        if abs(raw.info['sfreq'] - sfreq_target) > 1e-3:\n",
        "            raw.resample(sfreq_target, npad='auto', verbose=False)\n",
        "        picks = mne.pick_types(raw.info, eeg=True, exclude='bads')\n",
        "        try:\n",
        "            events, event_id = mne.events_from_annotations(raw, verbose=False)\n",
        "        except Exception:\n",
        "            events = []\n",
        "        for ev in events:\n",
        "            samp = int(ev[0])\n",
        "            start = int(samp + tmin * raw.info['sfreq'])\n",
        "            stop  = int(samp + tmax * raw.info['sfreq'])\n",
        "            if start < 0 or stop > raw.n_times:\n",
        "                continue\n",
        "            data = raw.get_data(picks=picks, start=start, stop=stop)\n",
        "            if data.shape[1] != nt:\n",
        "                if data.shape[1] > nt:\n",
        "                    data = data[:, :nt]\n",
        "                else:\n",
        "                    pad = np.zeros((len(picks), nt - data.shape[1]))\n",
        "                    data = np.hstack([data, pad])\n",
        "            code = ev[2]\n",
        "            lbl = 0 if (int(code) % 2 == 0) else 1\n",
        "            all_X.append(data)\n",
        "            all_y.append(lbl)\n",
        "        if ch_names is None:\n",
        "            ch_names = [raw.ch_names[i] for i in picks]\n",
        "    if len(all_X) == 0:\n",
        "        return np.zeros((0, len(picks) if picks is not None else 0, nt)), np.zeros((0,), dtype=int), ch_names\n",
        "    return np.stack(all_X, axis=0).astype(np.float32), np.array(all_y, dtype=int), ch_names\n",
        "\n",
        "# ----------------------------- EEG-ARNN Model -----------------------------\n",
        "class TFEMBlock(nn.Module):\n",
        "    def __init__(self, nch, F=16, k_t=15, pool=False, pool_k=4, drop=0.25):\n",
        "        super().__init__()\n",
        "        pad_t = (k_t - 1) // 2\n",
        "        self.conv = nn.Conv2d(1, F, kernel_size=(1, k_t), padding=(0, pad_t))\n",
        "        self.bn = nn.BatchNorm2d(F)\n",
        "        self.pw = nn.Conv2d(F, 1, kernel_size=1)\n",
        "        self.pool = nn.AvgPool2d((1, pool_k)) if pool else None\n",
        "        self.elu = nn.ELU()\n",
        "        self.drop = nn.Dropout(drop)\n",
        "    def forward(self, x):\n",
        "        b, nch, t = x.shape\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.elu(x)\n",
        "        x = self.pw(x)\n",
        "        if self.pool:\n",
        "            x = self.pool(x)\n",
        "        x = self.drop(x)\n",
        "        return x.squeeze(1)\n",
        "\n",
        "class CARM(nn.Module):\n",
        "    def __init__(self, Wref, tdim, drop=0.25):\n",
        "        super().__init__()\n",
        "        self.Wref = Wref\n",
        "        self.Theta = nn.Parameter(torch.randn(tdim, tdim) * 0.01)\n",
        "        self.elu = nn.ELU()\n",
        "        self.drop = nn.Dropout(drop)\n",
        "    def forward(self,x):\n",
        "        h = torch.einsum('ij,bjf->bif', self.Wref, x)\n",
        "        out = torch.einsum('bif,fg->big', h, self.Theta)\n",
        "        out = self.elu(out)\n",
        "        out = self.drop(out)\n",
        "        return out\n",
        "\n",
        "class EEG_ARNN(nn.Module):\n",
        "    def __init__(self, nch, T0, ncls=2, F=16, pool_k=4, rho=0.001):\n",
        "        super().__init__()\n",
        "        self.nch=nch; self.T0=T0; self.ncls=ncls; self.rho=rho\n",
        "        W0 = torch.ones(nch,nch) - torch.eye(nch)\n",
        "        Wt = W0 + torch.eye(nch)\n",
        "        D = Wt.sum(dim=1)\n",
        "        Dinv = torch.diag(1.0 / torch.sqrt(D + 1e-12))\n",
        "        self.W = nn.Parameter(Dinv @ Wt @ Dinv)\n",
        "        # TFEM + CARM blocks\n",
        "        self.tf1 = TFEMBlock(nch, F=F, k_t=15, pool=False)\n",
        "        self.c1  = CARM(self.W, tdim=T0)\n",
        "        self.tf2 = TFEMBlock(nch, F=F, k_t=15, pool=True, pool_k=pool_k)\n",
        "        T2 = T0 // pool_k\n",
        "        self.c2  = CARM(self.W, tdim=T2)\n",
        "        self.tf3 = TFEMBlock(nch, F=F, k_t=15, pool=True, pool_k=pool_k)\n",
        "        T3 = T2 // pool_k\n",
        "        self.c3  = CARM(self.W, tdim=T3)\n",
        "        # Fusion + classifier\n",
        "        self.fuse = nn.Conv2d(1,16,kernel_size=(nch,1))\n",
        "        self.bn = nn.BatchNorm2d(16)\n",
        "        self.drop = nn.Dropout(0.25)\n",
        "        self.elu = nn.ELU()\n",
        "        self.fc = nn.Linear(16*T3, ncls)\n",
        "    def forward(self,x):\n",
        "        x = self.tf1(x); x = self.c1(x)\n",
        "        x = self.tf2(x); x = self.c2(x)\n",
        "        x = self.tf3(x); x = self.c3(x)\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.fuse(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.elu(x)\n",
        "        x = self.drop(x)\n",
        "        x = x.squeeze(2)\n",
        "        b,oc,t = x.shape\n",
        "        x = x.view(b, oc*t)\n",
        "        return self.fc(x)\n",
        "\n",
        "# ----------------------------- Train / Eval Helpers -----------------------------\n",
        "def train_epoch(model,loader,opt,device,crit,rho):\n",
        "    model.train(); total=0; n=0\n",
        "    for xb,yb in loader:\n",
        "        xb=xb.to(device); yb=yb.to(device)\n",
        "        opt.zero_grad()\n",
        "        out=model(xb); loss=crit(out,yb)\n",
        "        loss.backward(); opt.step()\n",
        "        with torch.no_grad():\n",
        "            if model.W.grad is not None:\n",
        "                model.W.data = (1.0 - rho) * model.W.data - rho * model.W.grad.data\n",
        "                model.W.grad.zero_()\n",
        "        total += loss.item() * xb.size(0); n += xb.size(0)\n",
        "    return total / max(1,n)\n",
        "\n",
        "def eval_model(model,loader,device):\n",
        "    model.eval(); preds=[]; ys=[]\n",
        "    with torch.no_grad():\n",
        "        for xb,yb in loader:\n",
        "            xb=xb.to(device); yb=yb.to(device)\n",
        "            out=model(xb)\n",
        "            preds.append(out.argmax(dim=1).cpu().numpy())\n",
        "            ys.append(yb.cpu().numpy())\n",
        "    return np.concatenate(preds), np.concatenate(ys)\n",
        "\n",
        "# ----------------------------- AS Top-k Selection -----------------------------\n",
        "def select_topk_channels_AS(adj_matrix, k):\n",
        "    node_scores = torch.sum(torch.abs(adj_matrix), dim=1) + torch.diag(adj_matrix)\n",
        "    topk_indices = torch.topk(node_scores, k=k).indices.tolist()\n",
        "    return topk_indices\n",
        "\n",
        "# ----------------------------- Main Pipeline -----------------------------\n",
        "DATA_ROOT = 'bciciv2a/files'\n",
        "SUBJECT = 'S001'\n",
        "SUBJ_FOLDER = os.path.join(DATA_ROOT, SUBJECT)\n",
        "assert os.path.exists(SUBJ_FOLDER), f\"Folder not found: {SUBJ_FOLDER}\"\n",
        "\n",
        "X, y, chs = extract_physionet_subject(SUBJ_FOLDER)\n",
        "print(\"Extracted X:\", X.shape, \"y:\", y.shape, \"channels:\", len(chs))\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "EPOCHS, BATCH, LR = 5, 16, 1e-3\n",
        "k_top = 20  # top-k channels\n",
        "\n",
        "trained_models = []\n",
        "\n",
        "# ----------------------------- 10-fold CV training -----------------------------\n",
        "# ----------------------------- 10-fold CV training + evaluation -----------------------------\n",
        "full_accs, topk_accs = [], []\n",
        "\n",
        "for fold,(train_idx,val_idx) in enumerate(skf.split(X,y),1):\n",
        "    print(f\"\\n--- Fold {fold} ---\")\n",
        "    Xtr, ytr = X[train_idx], y[train_idx]\n",
        "    Xval, yval = X[val_idx], y[val_idx]\n",
        "\n",
        "    tr_loader = DataLoader(TensorDataset(torch.tensor(Xtr,dtype=torch.float32),torch.tensor(ytr)),\n",
        "                           batch_size=BATCH, shuffle=True)\n",
        "    val_loader = DataLoader(TensorDataset(torch.tensor(Xval,dtype=torch.float32),torch.tensor(yval)),\n",
        "                            batch_size=BATCH, shuffle=False)\n",
        "\n",
        "    # ---------------- Full-channel EEG-ARNN ----------------\n",
        "    model = EEG_ARNN(nch=X.shape[1], T0=X.shape[2], ncls=len(np.unique(y))).to(device)\n",
        "    params = [p for n,p in model.named_parameters() if n!='W' and p.requires_grad]\n",
        "    opt = torch.optim.Adam(params, lr=LR)\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "\n",
        "    for ep in range(1,EPOCHS+1):\n",
        "        loss = train_epoch(model, tr_loader, opt, device, crit, rho=model.rho)\n",
        "        if ep%max(1,EPOCHS//5)==0 or ep==1:\n",
        "            print(f\"Epoch {ep}/{EPOCHS} -> train_loss={loss:.4f}\")\n",
        "\n",
        "    preds, ytrue = eval_model(model, val_loader, device)\n",
        "    acc = accuracy_score(ytrue,preds)\n",
        "    full_accs.append(acc)\n",
        "    print(f\"Fold {fold} full-channel accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "    # ---------------- Select top-k channels ----------------\n",
        "    W_star = model.W.detach().cpu()\n",
        "    topk_channels = select_topk_channels_AS(W_star, k_top)\n",
        "    print(f\"Fold {fold} top-{k_top} channels:\", topk_channels)\n",
        "\n",
        "    # ---------------- Reduced dataset ----------------\n",
        "    Xtr_topk = Xtr[:, topk_channels, :]\n",
        "    Xval_topk = Xval[:, topk_channels, :]\n",
        "\n",
        "    tr_loader_topk = DataLoader(TensorDataset(torch.tensor(Xtr_topk,dtype=torch.float32),torch.tensor(ytr)),\n",
        "                                batch_size=BATCH, shuffle=True)\n",
        "    val_loader_topk = DataLoader(TensorDataset(torch.tensor(Xval_topk,dtype=torch.float32),torch.tensor(yval)),\n",
        "                                 batch_size=BATCH, shuffle=False)\n",
        "\n",
        "    # ---------------- Top-k EEG-ARNN ----------------\n",
        "    topk_model = EEG_ARNN(nch=k_top, T0=Xtr_topk.shape[2], ncls=len(np.unique(y))).to(device)\n",
        "    params = [p for n,p in topk_model.named_parameters() if n!='W' and p.requires_grad]\n",
        "    opt = torch.optim.Adam(params, lr=LR)\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "\n",
        "    for ep in range(1,EPOCHS+1):\n",
        "        loss = train_epoch(topk_model, tr_loader_topk, opt, device, crit, rho=topk_model.rho)\n",
        "        if ep%max(1,EPOCHS//5)==0 or ep==1:\n",
        "            print(f\"Top-k Epoch {ep}/{EPOCHS} -> train_loss={loss:.4f}\")\n",
        "\n",
        "    preds_topk, ytrue_topk = eval_model(topk_model, val_loader_topk, device)\n",
        "    acc_topk = accuracy_score(ytrue_topk,preds_topk)\n",
        "    topk_accs.append(acc_topk)\n",
        "    print(f\"Fold {fold} top-{k_top} EEG-ARNN accuracy: {acc_topk*100:.2f}%\")\n",
        "\n",
        "# ----------------------------- Summary -----------------------------\n",
        "print(\"\\n=== Cross-Validation Summary ===\")\n",
        "for f,(fa,ta) in enumerate(zip(full_accs, topk_accs),1):\n",
        "    print(f\"Fold {f}: Full-channel={fa*100:.2f}%, Top-{k_top}={ta*100:.2f}%\")\n",
        "print(f\"Average full-channel accuracy: {np.mean(full_accs)*100:.2f}%\")\n",
        "print(f\"Average top-{k_top} accuracy: {np.mean(topk_accs)*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCGNGkRI4osS",
        "outputId": "bb28e711-5d9c-45de-a805-a5f2c65725c9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted X: (362, 64, 512) y: (362,) channels: 64\n",
            "\n",
            "--- Fold 1 ---\n",
            "Epoch 1/5 -> train_loss=0.5967\n",
            "Epoch 2/5 -> train_loss=0.6062\n",
            "Epoch 3/5 -> train_loss=0.6056\n",
            "Epoch 4/5 -> train_loss=0.5801\n",
            "Epoch 5/5 -> train_loss=0.6128\n",
            "Fold 1 full-channel accuracy: 75.68%\n",
            "Fold 1 top-20 channels: [21, 35, 62, 6, 33, 37, 3, 4, 19, 56, 24, 43, 1, 54, 27, 2, 34, 11, 49, 5]\n",
            "Top-k Epoch 1/5 -> train_loss=0.6241\n",
            "Top-k Epoch 2/5 -> train_loss=0.5825\n",
            "Top-k Epoch 3/5 -> train_loss=0.5969\n",
            "Top-k Epoch 4/5 -> train_loss=0.5879\n",
            "Top-k Epoch 5/5 -> train_loss=0.5930\n",
            "Fold 1 top-20 EEG-ARNN accuracy: 75.68%\n",
            "\n",
            "--- Fold 2 ---\n",
            "Epoch 1/5 -> train_loss=0.6139\n",
            "Epoch 2/5 -> train_loss=0.6063\n",
            "Epoch 3/5 -> train_loss=0.5866\n",
            "Epoch 4/5 -> train_loss=0.5861\n",
            "Epoch 5/5 -> train_loss=0.5829\n",
            "Fold 2 full-channel accuracy: 75.68%\n",
            "Fold 2 top-20 channels: [9, 43, 50, 3, 36, 16, 14, 30, 47, 53, 5, 12, 10, 54, 6, 61, 28, 21, 18, 13]\n",
            "Top-k Epoch 1/5 -> train_loss=0.6305\n",
            "Top-k Epoch 2/5 -> train_loss=0.5856\n",
            "Top-k Epoch 3/5 -> train_loss=0.5965\n",
            "Top-k Epoch 4/5 -> train_loss=0.5352\n",
            "Top-k Epoch 5/5 -> train_loss=0.5778\n",
            "Fold 2 top-20 EEG-ARNN accuracy: 75.68%\n",
            "\n",
            "--- Fold 3 ---\n",
            "Epoch 1/5 -> train_loss=0.6210\n",
            "Epoch 2/5 -> train_loss=0.5763\n",
            "Epoch 3/5 -> train_loss=0.5932\n",
            "Epoch 4/5 -> train_loss=0.5783\n",
            "Epoch 5/5 -> train_loss=0.5825\n",
            "Fold 3 full-channel accuracy: 75.00%\n",
            "Fold 3 top-20 channels: [13, 45, 1, 19, 42, 38, 46, 39, 41, 24, 62, 6, 3, 26, 9, 54, 12, 28, 25, 37]\n",
            "Top-k Epoch 1/5 -> train_loss=0.5907\n",
            "Top-k Epoch 2/5 -> train_loss=0.6096\n",
            "Top-k Epoch 3/5 -> train_loss=0.6339\n",
            "Top-k Epoch 4/5 -> train_loss=0.6128\n",
            "Top-k Epoch 5/5 -> train_loss=0.5810\n",
            "Fold 3 top-20 EEG-ARNN accuracy: 75.00%\n",
            "\n",
            "--- Fold 4 ---\n",
            "Epoch 1/5 -> train_loss=0.5904\n",
            "Epoch 2/5 -> train_loss=0.6018\n",
            "Epoch 3/5 -> train_loss=0.5935\n",
            "Epoch 4/5 -> train_loss=0.5880\n",
            "Epoch 5/5 -> train_loss=0.5753\n",
            "Fold 4 full-channel accuracy: 75.00%\n",
            "Fold 4 top-20 channels: [51, 21, 56, 17, 45, 25, 48, 18, 29, 35, 43, 46, 38, 59, 37, 57, 42, 11, 39, 14]\n",
            "Top-k Epoch 1/5 -> train_loss=0.6349\n",
            "Top-k Epoch 2/5 -> train_loss=0.5723\n",
            "Top-k Epoch 3/5 -> train_loss=0.6089\n",
            "Top-k Epoch 4/5 -> train_loss=0.5815\n",
            "Top-k Epoch 5/5 -> train_loss=0.5866\n",
            "Fold 4 top-20 EEG-ARNN accuracy: 75.00%\n",
            "\n",
            "--- Fold 5 ---\n",
            "Epoch 1/5 -> train_loss=0.6240\n",
            "Epoch 2/5 -> train_loss=0.5986\n",
            "Epoch 3/5 -> train_loss=0.6021\n",
            "Epoch 4/5 -> train_loss=0.6105\n",
            "Epoch 5/5 -> train_loss=0.5874\n",
            "Fold 5 full-channel accuracy: 75.00%\n",
            "Fold 5 top-20 channels: [48, 41, 8, 16, 51, 55, 30, 59, 25, 58, 33, 47, 2, 9, 49, 53, 39, 18, 21, 29]\n",
            "Top-k Epoch 1/5 -> train_loss=0.6605\n",
            "Top-k Epoch 2/5 -> train_loss=0.5890\n",
            "Top-k Epoch 3/5 -> train_loss=0.5933\n",
            "Top-k Epoch 4/5 -> train_loss=0.5698\n",
            "Top-k Epoch 5/5 -> train_loss=0.6046\n",
            "Fold 5 top-20 EEG-ARNN accuracy: 75.00%\n",
            "\n",
            "--- Fold 6 ---\n",
            "Epoch 1/5 -> train_loss=0.5999\n",
            "Epoch 2/5 -> train_loss=0.5816\n",
            "Epoch 3/5 -> train_loss=0.6046\n",
            "Epoch 4/5 -> train_loss=0.5706\n",
            "Epoch 5/5 -> train_loss=0.5862\n",
            "Fold 6 full-channel accuracy: 25.00%\n",
            "Fold 6 top-20 channels: [49, 9, 20, 17, 51, 26, 29, 16, 34, 38, 19, 5, 7, 53, 47, 15, 10, 39, 31, 32]\n",
            "Top-k Epoch 1/5 -> train_loss=0.6197\n",
            "Top-k Epoch 2/5 -> train_loss=0.5920\n",
            "Top-k Epoch 3/5 -> train_loss=0.6056\n",
            "Top-k Epoch 4/5 -> train_loss=0.5894\n",
            "Top-k Epoch 5/5 -> train_loss=0.5893\n",
            "Fold 6 top-20 EEG-ARNN accuracy: 75.00%\n",
            "\n",
            "--- Fold 7 ---\n",
            "Epoch 1/5 -> train_loss=0.6390\n",
            "Epoch 2/5 -> train_loss=0.6035\n",
            "Epoch 3/5 -> train_loss=0.6341\n",
            "Epoch 4/5 -> train_loss=0.5988\n",
            "Epoch 5/5 -> train_loss=0.5861\n",
            "Fold 7 full-channel accuracy: 75.00%\n",
            "Fold 7 top-20 channels: [28, 48, 51, 49, 11, 5, 31, 60, 20, 30, 17, 62, 2, 15, 24, 9, 29, 3, 12, 53]\n",
            "Top-k Epoch 1/5 -> train_loss=0.6126\n",
            "Top-k Epoch 2/5 -> train_loss=0.5936\n",
            "Top-k Epoch 3/5 -> train_loss=0.5893\n",
            "Top-k Epoch 4/5 -> train_loss=0.5843\n",
            "Top-k Epoch 5/5 -> train_loss=0.5682\n",
            "Fold 7 top-20 EEG-ARNN accuracy: 75.00%\n",
            "\n",
            "--- Fold 8 ---\n",
            "Epoch 1/5 -> train_loss=0.5787\n",
            "Epoch 2/5 -> train_loss=0.6223\n",
            "Epoch 3/5 -> train_loss=0.6085\n",
            "Epoch 4/5 -> train_loss=0.5974\n",
            "Epoch 5/5 -> train_loss=0.6148\n",
            "Fold 8 full-channel accuracy: 75.00%\n",
            "Fold 8 top-20 channels: [36, 20, 45, 57, 12, 53, 55, 48, 44, 24, 30, 16, 61, 49, 47, 21, 7, 0, 18, 37]\n",
            "Top-k Epoch 1/5 -> train_loss=0.5789\n",
            "Top-k Epoch 2/5 -> train_loss=0.6106\n",
            "Top-k Epoch 3/5 -> train_loss=0.6033\n",
            "Top-k Epoch 4/5 -> train_loss=0.5897\n",
            "Top-k Epoch 5/5 -> train_loss=0.5812\n",
            "Fold 8 top-20 EEG-ARNN accuracy: 75.00%\n",
            "\n",
            "--- Fold 9 ---\n",
            "Epoch 1/5 -> train_loss=0.6533\n",
            "Epoch 2/5 -> train_loss=0.6096\n",
            "Epoch 3/5 -> train_loss=0.6241\n",
            "Epoch 4/5 -> train_loss=0.5936\n",
            "Epoch 5/5 -> train_loss=0.5679\n",
            "Fold 9 full-channel accuracy: 75.00%\n",
            "Fold 9 top-20 channels: [61, 12, 49, 0, 21, 9, 39, 20, 40, 36, 43, 60, 28, 19, 6, 8, 51, 30, 16, 1]\n",
            "Top-k Epoch 1/5 -> train_loss=0.6448\n",
            "Top-k Epoch 2/5 -> train_loss=0.6022\n",
            "Top-k Epoch 3/5 -> train_loss=0.5688\n",
            "Top-k Epoch 4/5 -> train_loss=0.5963\n",
            "Top-k Epoch 5/5 -> train_loss=0.5870\n",
            "Fold 9 top-20 EEG-ARNN accuracy: 75.00%\n",
            "\n",
            "--- Fold 10 ---\n",
            "Epoch 1/5 -> train_loss=0.6600\n",
            "Epoch 2/5 -> train_loss=0.5869\n",
            "Epoch 3/5 -> train_loss=0.5892\n",
            "Epoch 4/5 -> train_loss=0.5846\n",
            "Epoch 5/5 -> train_loss=0.5964\n",
            "Fold 10 full-channel accuracy: 75.00%\n",
            "Fold 10 top-20 channels: [51, 27, 3, 59, 37, 60, 61, 62, 19, 24, 57, 40, 29, 21, 6, 49, 34, 38, 25, 13]\n",
            "Top-k Epoch 1/5 -> train_loss=0.6172\n",
            "Top-k Epoch 2/5 -> train_loss=0.6104\n",
            "Top-k Epoch 3/5 -> train_loss=0.5972\n",
            "Top-k Epoch 4/5 -> train_loss=0.6040\n",
            "Top-k Epoch 5/5 -> train_loss=0.5842\n",
            "Fold 10 top-20 EEG-ARNN accuracy: 75.00%\n",
            "\n",
            "=== Cross-Validation Summary ===\n",
            "Fold 1: Full-channel=75.68%, Top-20=75.68%\n",
            "Fold 2: Full-channel=75.68%, Top-20=75.68%\n",
            "Fold 3: Full-channel=75.00%, Top-20=75.00%\n",
            "Fold 4: Full-channel=75.00%, Top-20=75.00%\n",
            "Fold 5: Full-channel=75.00%, Top-20=75.00%\n",
            "Fold 6: Full-channel=25.00%, Top-20=75.00%\n",
            "Fold 7: Full-channel=75.00%, Top-20=75.00%\n",
            "Fold 8: Full-channel=75.00%, Top-20=75.00%\n",
            "Fold 9: Full-channel=75.00%, Top-20=75.00%\n",
            "Fold 10: Full-channel=75.00%, Top-20=75.00%\n",
            "Average full-channel accuracy: 70.14%\n",
            "Average top-20 accuracy: 75.14%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjORQBfF6dxbVv8AOGUyOb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}