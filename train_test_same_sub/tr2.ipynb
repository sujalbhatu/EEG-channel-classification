{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e51773f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy.__version__ = 2.3.3\n",
      "mne.__version__ = 1.10.1\n"
     ]
    }
   ],
   "source": [
    "# Compatibility patch: fix NumPy>=2.0 / old MNE fromstring usage\n",
    "import numpy as np\n",
    "import inspect\n",
    "\n",
    "# Only patch if necessary\n",
    "if hasattr(np, \"fromstring\"):\n",
    "    _orig_fromstring = np.fromstring\n",
    "    def _safe_fromstring(string, dtype=float, sep=\"\"):\n",
    "        try:\n",
    "            # try original behaviour (works for NumPy < 2.0 or text-mode)\n",
    "            return _orig_fromstring(string, dtype=dtype, sep=sep)\n",
    "        except ValueError:\n",
    "            # fallback for binary-mode usage in older code (e.g. MNE's GDF reader)\n",
    "            # ensure we have bytes\n",
    "            if isinstance(string, str):\n",
    "                string = string.encode()\n",
    "            # if it is already bytes-like or memoryview, np.frombuffer works\n",
    "            return np.frombuffer(string, dtype=dtype)\n",
    "    np.fromstring = _safe_fromstring\n",
    "\n",
    "# Optional: show versions for debugging\n",
    "import sys\n",
    "print(\"numpy.__version__ =\", np.__version__)\n",
    "try:\n",
    "    import mne\n",
    "    print(\"mne.__version__ =\", mne.__version__)\n",
    "except Exception as e:\n",
    "    print(\"mne import not executed yet (that's OK).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c916cfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded OK. n_channels: 25 sfreq: 250.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "raw = mne.io.read_raw_gdf(\"../BCICIV_2a_gdf/A01T.gdf\", preload=False, verbose=False)\n",
    "print(\"Loaded OK. n_channels:\", len(raw.ch_names), \"sfreq:\", raw.info['sfreq'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "663ec4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "\n",
      "======================== A01 ========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loader] A01T.gdf annotation counts sample: [('32766', 9), ('276', 1), ('277', 1), ('1072', 1), ('768', 288), ('772', 72), ('771', 72), ('770', 72), ('769', 72), ('1023', 15)]\n",
      "[loader] found canonical MI cues (769-772).\n",
      "[loader] mapping desc->label: {'769': 0, '770': 1, '771': 2, '772': 3}\n",
      "[loader] chosen counts: {'769': 72, '770': 72, '771': 72, '772': 72}\n",
      "[loader] extracted epochs shape: (288, 25, 512), label distribution: [72 72 72 72]\n",
      "[A01] train epochs shape: (288, 25, 512), classes: [72 72 72 72]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A01] NOTE: evaluation file does NOT contain MI cues (we will use stratified CV on training only).\n",
      "[A01] fold 1 ep 001 train_loss=1.4888 val_acc=0.2586\n",
      "[A01] fold 1 ep 010 train_loss=0.5656 val_acc=0.2414\n",
      "[A01] fold 1 ep 020 train_loss=0.0063 val_acc=0.3448\n",
      "[A01] fold 1 ep 030 train_loss=0.0017 val_acc=0.3276\n",
      "[A01] fold 1 early stopping at ep 32, best_val=0.3448 (epoch 20)\n",
      "[A01] fold 1 best_val_acc = 0.3448\n",
      "[A01] fold 2 ep 001 train_loss=1.4502 val_acc=0.2414\n",
      "[A01] fold 2 ep 010 train_loss=0.2811 val_acc=0.3103\n",
      "[A01] fold 2 early stopping at ep 17, best_val=0.3966 (epoch 5)\n",
      "[A01] fold 2 best_val_acc = 0.3966\n",
      "[A01] fold 3 ep 001 train_loss=1.5286 val_acc=0.2586\n",
      "[A01] fold 3 ep 010 train_loss=0.0357 val_acc=0.1897\n",
      "[A01] fold 3 early stopping at ep 16, best_val=0.2759 (epoch 4)\n",
      "[A01] fold 3 best_val_acc = 0.2759\n",
      "[A01] fold 4 ep 001 train_loss=1.5428 val_acc=0.2632\n",
      "[A01] fold 4 ep 010 train_loss=0.0569 val_acc=0.2456\n",
      "[A01] fold 4 early stopping at ep 19, best_val=0.3158 (epoch 7)\n",
      "[A01] fold 4 best_val_acc = 0.3158\n",
      "[A01] fold 5 ep 001 train_loss=1.4735 val_acc=0.2456\n",
      "[A01] fold 5 ep 010 train_loss=0.0960 val_acc=0.3333\n",
      "[A01] fold 5 early stopping at ep 18, best_val=0.3860 (epoch 6)\n",
      "[A01] fold 5 best_val_acc = 0.3860\n",
      "[A01] CV mean ± std = 0.3438 ± 0.0446\n",
      "\n",
      "======================== A02 ========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loader] A02T.gdf annotation counts sample: [('32766', 9), ('276', 1), ('277', 1), ('1072', 1), ('768', 288), ('769', 72), ('770', 72), ('771', 72), ('772', 72), ('1023', 18)]\n",
      "[loader] found canonical MI cues (769-772).\n",
      "[loader] mapping desc->label: {'769': 0, '770': 1, '771': 2, '772': 3}\n",
      "[loader] chosen counts: {'769': 72, '770': 72, '771': 72, '772': 72}\n",
      "[loader] extracted epochs shape: (288, 25, 512), label distribution: [72 72 72 72]\n",
      "[A02] train epochs shape: (288, 25, 512), classes: [72 72 72 72]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A02] NOTE: evaluation file does NOT contain MI cues (we will use stratified CV on training only).\n",
      "[A02] fold 1 ep 001 train_loss=1.4868 val_acc=0.2414\n",
      "[A02] fold 1 ep 010 train_loss=0.6964 val_acc=0.2759\n",
      "[A02] fold 1 early stopping at ep 17, best_val=0.2931 (epoch 5)\n",
      "[A02] fold 1 best_val_acc = 0.2931\n",
      "[A02] fold 2 ep 001 train_loss=1.5230 val_acc=0.2586\n",
      "[A02] fold 2 ep 010 train_loss=0.0532 val_acc=0.2241\n",
      "[A02] fold 2 ep 020 train_loss=0.0026 val_acc=0.2931\n",
      "[A02] fold 2 early stopping at ep 26, best_val=0.2931 (epoch 14)\n",
      "[A02] fold 2 best_val_acc = 0.2931\n",
      "[A02] fold 3 ep 001 train_loss=1.4906 val_acc=0.2414\n",
      "[A02] fold 3 ep 010 train_loss=0.0095 val_acc=0.1034\n",
      "[A02] fold 3 early stopping at ep 13, best_val=0.2414 (epoch 1)\n",
      "[A02] fold 3 best_val_acc = 0.2414\n",
      "[A02] fold 4 ep 001 train_loss=1.4800 val_acc=0.2456\n",
      "[A02] fold 4 ep 010 train_loss=0.1007 val_acc=0.2105\n",
      "[A02] fold 4 early stopping at ep 13, best_val=0.2456 (epoch 1)\n",
      "[A02] fold 4 best_val_acc = 0.2456\n",
      "[A02] fold 5 ep 001 train_loss=1.5021 val_acc=0.2456\n",
      "[A02] fold 5 ep 010 train_loss=0.0247 val_acc=0.2105\n",
      "[A02] fold 5 early stopping at ep 16, best_val=0.2982 (epoch 4)\n",
      "[A02] fold 5 best_val_acc = 0.2982\n",
      "[A02] CV mean ± std = 0.2743 ± 0.0252\n",
      "\n",
      "======================== A03 ========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loader] A03T.gdf annotation counts sample: [('32766', 9), ('276', 1), ('277', 1), ('1072', 1), ('768', 288), ('769', 72), ('770', 72), ('771', 72), ('772', 72), ('1023', 18)]\n",
      "[loader] found canonical MI cues (769-772).\n",
      "[loader] mapping desc->label: {'769': 0, '770': 1, '771': 2, '772': 3}\n",
      "[loader] chosen counts: {'769': 72, '770': 72, '771': 72, '772': 72}\n",
      "[loader] extracted epochs shape: (288, 25, 512), label distribution: [72 72 72 72]\n",
      "[A03] train epochs shape: (288, 25, 512), classes: [72 72 72 72]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A03] NOTE: evaluation file does NOT contain MI cues (we will use stratified CV on training only).\n",
      "[A03] fold 1 ep 001 train_loss=1.5131 val_acc=0.2586\n",
      "[A03] fold 1 ep 010 train_loss=0.2493 val_acc=0.2069\n",
      "[A03] fold 1 ep 020 train_loss=0.0025 val_acc=0.2069\n",
      "[A03] fold 1 early stopping at ep 20, best_val=0.3103 (epoch 8)\n",
      "[A03] fold 1 best_val_acc = 0.3103\n",
      "[A03] fold 2 ep 001 train_loss=1.5229 val_acc=0.2586\n",
      "[A03] fold 2 ep 010 train_loss=0.6576 val_acc=0.2241\n",
      "[A03] fold 2 ep 020 train_loss=0.0041 val_acc=0.2414\n",
      "[A03] fold 2 early stopping at ep 20, best_val=0.2931 (epoch 8)\n",
      "[A03] fold 2 best_val_acc = 0.2931\n",
      "[A03] fold 3 ep 001 train_loss=1.4874 val_acc=0.2414\n",
      "[A03] fold 3 ep 010 train_loss=0.6101 val_acc=0.2241\n",
      "[A03] fold 3 early stopping at ep 18, best_val=0.3276 (epoch 6)\n",
      "[A03] fold 3 best_val_acc = 0.3276\n",
      "[A03] fold 4 ep 001 train_loss=1.5481 val_acc=0.2632\n",
      "[A03] fold 4 ep 010 train_loss=0.0108 val_acc=0.1754\n",
      "[A03] fold 4 early stopping at ep 15, best_val=0.2982 (epoch 3)\n",
      "[A03] fold 4 best_val_acc = 0.2982\n",
      "[A03] fold 5 ep 001 train_loss=1.4930 val_acc=0.2456\n",
      "[A03] fold 5 ep 010 train_loss=1.0204 val_acc=0.2632\n",
      "[A03] fold 5 ep 020 train_loss=0.0057 val_acc=0.2281\n",
      "[A03] fold 5 early stopping at ep 24, best_val=0.3158 (epoch 12)\n",
      "[A03] fold 5 best_val_acc = 0.3158\n",
      "[A03] CV mean ± std = 0.3090 ± 0.0123\n",
      "\n",
      "======================== A04 ========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loader] A04T.gdf annotation counts sample: [('32766', 7), ('1072', 1), ('768', 288), ('772', 72), ('769', 72), ('770', 72), ('771', 72), ('1023', 26)]\n",
      "[loader] found canonical MI cues (769-772).\n",
      "[loader] mapping desc->label: {'769': 0, '770': 1, '771': 2, '772': 3}\n",
      "[loader] chosen counts: {'769': 72, '770': 72, '771': 72, '772': 72}\n",
      "[loader] extracted epochs shape: (288, 25, 512), label distribution: [72 72 72 72]\n",
      "[A04] train epochs shape: (288, 25, 512), classes: [72 72 72 72]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A04] NOTE: evaluation file does NOT contain MI cues (we will use stratified CV on training only).\n",
      "[A04] fold 1 ep 001 train_loss=1.4682 val_acc=0.2586\n",
      "[A04] fold 1 ep 010 train_loss=0.5921 val_acc=0.1897\n",
      "[A04] fold 1 early stopping at ep 18, best_val=0.2759 (epoch 6)\n",
      "[A04] fold 1 best_val_acc = 0.2759\n",
      "[A04] fold 2 ep 001 train_loss=1.5038 val_acc=0.2586\n",
      "[A04] fold 2 ep 010 train_loss=0.4194 val_acc=0.2241\n",
      "[A04] fold 2 early stopping at ep 16, best_val=0.3276 (epoch 4)\n",
      "[A04] fold 2 best_val_acc = 0.3276\n",
      "[A04] fold 3 ep 001 train_loss=1.5610 val_acc=0.2586\n",
      "[A04] fold 3 ep 010 train_loss=0.0915 val_acc=0.2586\n",
      "[A04] fold 3 early stopping at ep 16, best_val=0.2759 (epoch 4)\n",
      "[A04] fold 3 best_val_acc = 0.2759\n",
      "[A04] fold 4 ep 001 train_loss=1.4865 val_acc=0.2632\n",
      "[A04] fold 4 ep 010 train_loss=0.0925 val_acc=0.2982\n",
      "[A04] fold 4 early stopping at ep 19, best_val=0.4035 (epoch 7)\n",
      "[A04] fold 4 best_val_acc = 0.4035\n",
      "[A04] fold 5 ep 001 train_loss=1.4596 val_acc=0.2456\n",
      "[A04] fold 5 ep 010 train_loss=0.1273 val_acc=0.2456\n",
      "[A04] fold 5 early stopping at ep 18, best_val=0.2982 (epoch 6)\n",
      "[A04] fold 5 best_val_acc = 0.2982\n",
      "[A04] CV mean ± std = 0.3162 ± 0.0476\n",
      "\n",
      "======================== A05 ========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loader] A05T.gdf annotation counts sample: [('32766', 9), ('276', 1), ('277', 1), ('1072', 1), ('768', 288), ('1023', 26), ('769', 72), ('770', 72), ('771', 72), ('772', 72)]\n",
      "[loader] found canonical MI cues (769-772).\n",
      "[loader] mapping desc->label: {'769': 0, '770': 1, '771': 2, '772': 3}\n",
      "[loader] chosen counts: {'769': 72, '770': 72, '771': 72, '772': 72}\n",
      "[loader] extracted epochs shape: (288, 25, 512), label distribution: [72 72 72 72]\n",
      "[A05] train epochs shape: (288, 25, 512), classes: [72 72 72 72]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A05] NOTE: evaluation file does NOT contain MI cues (we will use stratified CV on training only).\n",
      "[A05] fold 1 ep 001 train_loss=1.4670 val_acc=0.2414\n",
      "[A05] fold 1 ep 010 train_loss=0.0242 val_acc=0.2241\n",
      "[A05] fold 1 early stopping at ep 17, best_val=0.3103 (epoch 5)\n",
      "[A05] fold 1 best_val_acc = 0.3103\n",
      "[A05] fold 2 ep 001 train_loss=1.4611 val_acc=0.2586\n",
      "[A05] fold 2 ep 010 train_loss=0.2694 val_acc=0.2069\n",
      "[A05] fold 2 early stopping at ep 18, best_val=0.3103 (epoch 6)\n",
      "[A05] fold 2 best_val_acc = 0.3103\n",
      "[A05] fold 3 ep 001 train_loss=1.5188 val_acc=0.2414\n",
      "[A05] fold 3 ep 010 train_loss=0.3930 val_acc=0.2931\n",
      "[A05] fold 3 early stopping at ep 19, best_val=0.3621 (epoch 7)\n",
      "[A05] fold 3 best_val_acc = 0.3621\n",
      "[A05] fold 4 ep 001 train_loss=1.4658 val_acc=0.2632\n",
      "[A05] fold 4 ep 010 train_loss=0.0366 val_acc=0.2982\n",
      "[A05] fold 4 early stopping at ep 18, best_val=0.3684 (epoch 6)\n",
      "[A05] fold 4 best_val_acc = 0.3684\n",
      "[A05] fold 5 ep 001 train_loss=1.5242 val_acc=0.2456\n",
      "[A05] fold 5 ep 010 train_loss=0.5350 val_acc=0.2807\n",
      "[A05] fold 5 ep 020 train_loss=0.0032 val_acc=0.3158\n",
      "[A05] fold 5 early stopping at ep 21, best_val=0.3333 (epoch 9)\n",
      "[A05] fold 5 best_val_acc = 0.3333\n",
      "[A05] CV mean ± std = 0.3369 ± 0.0247\n",
      "\n",
      "======================== A06 ========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loader] A06T.gdf annotation counts sample: [('32766', 9), ('276', 1), ('277', 1), ('1072', 1), ('768', 288), ('772', 72), ('770', 72), ('769', 72), ('771', 72), ('1023', 69)]\n",
      "[loader] found canonical MI cues (769-772).\n",
      "[loader] mapping desc->label: {'769': 0, '770': 1, '771': 2, '772': 3}\n",
      "[loader] chosen counts: {'769': 72, '770': 72, '771': 72, '772': 72}\n",
      "[loader] extracted epochs shape: (288, 25, 512), label distribution: [72 72 72 72]\n",
      "[A06] train epochs shape: (288, 25, 512), classes: [72 72 72 72]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A06] NOTE: evaluation file does NOT contain MI cues (we will use stratified CV on training only).\n",
      "[A06] fold 1 ep 001 train_loss=1.4467 val_acc=0.2586\n",
      "[A06] fold 1 ep 010 train_loss=0.2603 val_acc=0.3103\n",
      "[A06] fold 1 ep 020 train_loss=0.0032 val_acc=0.2414\n",
      "[A06] fold 1 early stopping at ep 21, best_val=0.3103 (epoch 9)\n",
      "[A06] fold 1 best_val_acc = 0.3103\n",
      "[A06] fold 2 ep 001 train_loss=1.5205 val_acc=0.2586\n",
      "[A06] fold 2 ep 010 train_loss=0.0185 val_acc=0.3448\n",
      "[A06] fold 2 early stopping at ep 19, best_val=0.3793 (epoch 7)\n",
      "[A06] fold 2 best_val_acc = 0.3793\n",
      "[A06] fold 3 ep 001 train_loss=1.4177 val_acc=0.2414\n",
      "[A06] fold 3 ep 010 train_loss=0.0411 val_acc=0.3966\n",
      "[A06] fold 3 ep 020 train_loss=0.0026 val_acc=0.4483\n",
      "[A06] fold 3 early stopping at ep 24, best_val=0.4828 (epoch 12)\n",
      "[A06] fold 3 best_val_acc = 0.4828\n",
      "[A06] fold 4 ep 001 train_loss=1.4145 val_acc=0.2456\n",
      "[A06] fold 4 ep 010 train_loss=0.2614 val_acc=0.2456\n",
      "[A06] fold 4 ep 020 train_loss=0.0026 val_acc=0.2807\n",
      "[A06] fold 4 early stopping at ep 25, best_val=0.3158 (epoch 13)\n",
      "[A06] fold 4 best_val_acc = 0.3158\n",
      "[A06] fold 5 ep 001 train_loss=1.5077 val_acc=0.2456\n",
      "[A06] fold 5 ep 010 train_loss=0.9303 val_acc=0.2281\n",
      "[A06] fold 5 ep 020 train_loss=0.0035 val_acc=0.3684\n",
      "[A06] fold 5 early stopping at ep 23, best_val=0.3860 (epoch 11)\n",
      "[A06] fold 5 best_val_acc = 0.3860\n",
      "[A06] CV mean ± std = 0.3748 ± 0.0623\n",
      "\n",
      "======================== A07 ========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loader] A07T.gdf annotation counts sample: [('32766', 9), ('276', 1), ('277', 1), ('1072', 1), ('768', 288), ('769', 72), ('770', 72), ('771', 72), ('772', 72), ('1023', 17)]\n",
      "[loader] found canonical MI cues (769-772).\n",
      "[loader] mapping desc->label: {'769': 0, '770': 1, '771': 2, '772': 3}\n",
      "[loader] chosen counts: {'769': 72, '770': 72, '771': 72, '772': 72}\n",
      "[loader] extracted epochs shape: (288, 25, 512), label distribution: [72 72 72 72]\n",
      "[A07] train epochs shape: (288, 25, 512), classes: [72 72 72 72]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A07] NOTE: evaluation file does NOT contain MI cues (we will use stratified CV on training only).\n",
      "[A07] fold 1 ep 001 train_loss=1.5095 val_acc=0.2586\n",
      "[A07] fold 1 ep 010 train_loss=0.1886 val_acc=0.3621\n",
      "[A07] fold 1 ep 020 train_loss=0.0035 val_acc=0.3966\n",
      "[A07] fold 1 ep 030 train_loss=0.0017 val_acc=0.3966\n",
      "[A07] fold 1 early stopping at ep 32, best_val=0.3966 (epoch 20)\n",
      "[A07] fold 1 best_val_acc = 0.3966\n",
      "[A07] fold 2 ep 001 train_loss=1.4969 val_acc=0.2586\n",
      "[A07] fold 2 ep 010 train_loss=0.1568 val_acc=0.1724\n",
      "[A07] fold 2 early stopping at ep 13, best_val=0.2586 (epoch 1)\n",
      "[A07] fold 2 best_val_acc = 0.2586\n",
      "[A07] fold 3 ep 001 train_loss=1.4820 val_acc=0.2414\n",
      "[A07] fold 3 ep 010 train_loss=0.0127 val_acc=0.3621\n",
      "[A07] fold 3 ep 020 train_loss=0.0019 val_acc=0.3793\n",
      "[A07] fold 3 early stopping at ep 21, best_val=0.3966 (epoch 9)\n",
      "[A07] fold 3 best_val_acc = 0.3966\n",
      "[A07] fold 4 ep 001 train_loss=1.4718 val_acc=0.2456\n",
      "[A07] fold 4 ep 010 train_loss=0.0236 val_acc=0.3333\n",
      "[A07] fold 4 early stopping at ep 19, best_val=0.3509 (epoch 7)\n",
      "[A07] fold 4 best_val_acc = 0.3509\n",
      "[A07] fold 5 ep 001 train_loss=1.4829 val_acc=0.2456\n",
      "[A07] fold 5 ep 010 train_loss=0.0995 val_acc=0.3158\n",
      "[A07] fold 5 ep 020 train_loss=0.0027 val_acc=0.2982\n",
      "[A07] fold 5 early stopping at ep 21, best_val=0.3509 (epoch 9)\n",
      "[A07] fold 5 best_val_acc = 0.3509\n",
      "[A07] CV mean ± std = 0.3507 ± 0.0504\n",
      "\n",
      "======================== A08 ========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loader] A08T.gdf annotation counts sample: [('32766', 9), ('276', 1), ('277', 1), ('1072', 1), ('768', 288), ('769', 72), ('770', 72), ('1023', 24), ('771', 72), ('772', 72)]\n",
      "[loader] found canonical MI cues (769-772).\n",
      "[loader] mapping desc->label: {'769': 0, '770': 1, '771': 2, '772': 3}\n",
      "[loader] chosen counts: {'769': 72, '770': 72, '771': 72, '772': 72}\n",
      "[loader] extracted epochs shape: (288, 25, 512), label distribution: [72 72 72 72]\n",
      "[A08] train epochs shape: (288, 25, 512), classes: [72 72 72 72]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A08] NOTE: evaluation file does NOT contain MI cues (we will use stratified CV on training only).\n",
      "[A08] fold 1 ep 001 train_loss=1.4774 val_acc=0.2586\n",
      "[A08] fold 1 ep 010 train_loss=0.1127 val_acc=0.3621\n",
      "[A08] fold 1 ep 020 train_loss=0.0025 val_acc=0.3621\n",
      "[A08] fold 1 early stopping at ep 29, best_val=0.3966 (epoch 17)\n",
      "[A08] fold 1 best_val_acc = 0.3966\n",
      "[A08] fold 2 ep 001 train_loss=1.4811 val_acc=0.2414\n",
      "[A08] fold 2 ep 010 train_loss=0.5198 val_acc=0.2241\n",
      "[A08] fold 2 ep 020 train_loss=0.0034 val_acc=0.2931\n",
      "[A08] fold 2 early stopping at ep 26, best_val=0.3621 (epoch 14)\n",
      "[A08] fold 2 best_val_acc = 0.3621\n",
      "[A08] fold 3 ep 001 train_loss=1.4813 val_acc=0.2414\n",
      "[A08] fold 3 ep 010 train_loss=0.1351 val_acc=0.2931\n",
      "[A08] fold 3 early stopping at ep 18, best_val=0.3276 (epoch 6)\n",
      "[A08] fold 3 best_val_acc = 0.3276\n",
      "[A08] fold 4 ep 001 train_loss=1.4133 val_acc=0.2456\n",
      "[A08] fold 4 ep 010 train_loss=0.0155 val_acc=0.2982\n",
      "[A08] fold 4 early stopping at ep 19, best_val=0.3509 (epoch 7)\n",
      "[A08] fold 4 best_val_acc = 0.3509\n",
      "[A08] fold 5 ep 001 train_loss=1.4795 val_acc=0.2456\n",
      "[A08] fold 5 ep 010 train_loss=0.1597 val_acc=0.2632\n",
      "[A08] fold 5 early stopping at ep 18, best_val=0.3684 (epoch 6)\n",
      "[A08] fold 5 best_val_acc = 0.3684\n",
      "[A08] CV mean ± std = 0.3611 ± 0.0225\n",
      "\n",
      "======================== A09 ========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loader] A09T.gdf annotation counts sample: [('32766', 9), ('276', 1), ('277', 1), ('1072', 1), ('768', 288), ('1023', 51), ('772', 72), ('770', 72), ('769', 72), ('771', 72)]\n",
      "[loader] found canonical MI cues (769-772).\n",
      "[loader] mapping desc->label: {'769': 0, '770': 1, '771': 2, '772': 3}\n",
      "[loader] chosen counts: {'769': 72, '770': 72, '771': 72, '772': 72}\n",
      "[loader] extracted epochs shape: (288, 25, 512), label distribution: [72 72 72 72]\n",
      "[A09] train epochs shape: (288, 25, 512), classes: [72 72 72 72]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sujal Bhatu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[A09] NOTE: evaluation file does NOT contain MI cues (we will use stratified CV on training only).\n",
      "[A09] fold 1 ep 001 train_loss=1.5074 val_acc=0.2414\n",
      "[A09] fold 1 ep 010 train_loss=0.1311 val_acc=0.3103\n",
      "[A09] fold 1 ep 020 train_loss=0.0030 val_acc=0.3448\n",
      "[A09] fold 1 early stopping at ep 25, best_val=0.3793 (epoch 13)\n",
      "[A09] fold 1 best_val_acc = 0.3793\n",
      "[A09] fold 2 ep 001 train_loss=1.4682 val_acc=0.2414\n",
      "[A09] fold 2 ep 010 train_loss=0.0380 val_acc=0.3448\n",
      "[A09] fold 2 early stopping at ep 18, best_val=0.3621 (epoch 6)\n",
      "[A09] fold 2 best_val_acc = 0.3621\n",
      "[A09] fold 3 ep 001 train_loss=1.5424 val_acc=0.2414\n",
      "[A09] fold 3 ep 010 train_loss=1.3646 val_acc=0.2414\n",
      "[A09] fold 3 ep 020 train_loss=0.0111 val_acc=0.2241\n",
      "[A09] fold 3 early stopping at ep 23, best_val=0.2931 (epoch 11)\n",
      "[A09] fold 3 best_val_acc = 0.2931\n",
      "[A09] fold 4 ep 001 train_loss=1.5318 val_acc=0.2456\n",
      "[A09] fold 4 ep 010 train_loss=0.4732 val_acc=0.3158\n",
      "[A09] fold 4 ep 020 train_loss=0.0049 val_acc=0.2807\n",
      "[A09] fold 4 early stopping at ep 22, best_val=0.3158 (epoch 10)\n",
      "[A09] fold 4 best_val_acc = 0.3158\n",
      "[A09] fold 5 ep 001 train_loss=1.4714 val_acc=0.2456\n",
      "[A09] fold 5 ep 010 train_loss=0.0122 val_acc=0.3158\n",
      "[A09] fold 5 early stopping at ep 18, best_val=0.3684 (epoch 6)\n",
      "[A09] fold 5 best_val_acc = 0.3684\n",
      "[A09] CV mean ± std = 0.3437 ± 0.0333\n",
      "\n",
      "\n",
      "====== SUBJECT-WISE SUMMARY ======\n",
      "A01: mean acc = 34.38%, std = 4.46%, trials=288\n",
      "A02: mean acc = 27.43%, std = 2.52%, trials=288\n",
      "A03: mean acc = 30.90%, std = 1.23%, trials=288\n",
      "A04: mean acc = 31.62%, std = 4.76%, trials=288\n",
      "A05: mean acc = 33.69%, std = 2.47%, trials=288\n",
      "A06: mean acc = 37.48%, std = 6.23%, trials=288\n",
      "A07: mean acc = 35.07%, std = 5.04%, trials=288\n",
      "A08: mean acc = 36.11%, std = 2.25%, trials=288\n",
      "A09: mean acc = 34.37%, std = 3.33%, trials=288\n",
      "\n",
      "Overall mean (subjects) = 33.45% ± 2.86%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: many AxxE.gdf files in your folder do not contain MI cue annotations (769..772).\n",
      "      That's why we used stratified CV on each subject's training session (AxxT.gdf).\n",
      "If you have separate ground-truth label files for evaluation sessions, tell me their filenames and I'll show how to combine them.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Subject-wise 5-fold CV pipeline (robust loader + EEG-ARNN) ----------\n",
    "# Paste & run this single cell in your notebook\n",
    "\n",
    "import os, re, random, math\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import mne\n",
    "import torch, torch.nn as nn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------ Config & reproducibility ------------------\n",
    "DATA_ROOT = \"./../BCICIV_2a_gdf\"   # ← adjust if needed\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)\n",
    "\n",
    "N_SPLITS = 5           # stratified CV folds per subject\n",
    "EPOCHS = 60            # per-fold epochs (reduce if CPU too slow)\n",
    "BATCH = 32\n",
    "LR = 1e-3\n",
    "PATIENCE = 12          # early-stop patience (per fold)\n",
    "TARGET_SFREQ = 128.0\n",
    "TMIN, TMAX = 0.0, 4.0\n",
    "NT = int((TMAX - TMIN) * TARGET_SFREQ)\n",
    "\n",
    "\n",
    "# ------------------ Robust loader (uses 769..772 if present) ------------------\n",
    "def load_bci_gdf_robust(path,\n",
    "                        l_freq=8.0, h_freq=30.0,\n",
    "                        target_sfreq=TARGET_SFREQ, tmin=TMIN, tmax=TMAX,\n",
    "                        verbose=True):\n",
    "    raw = mne.io.read_raw_gdf(path, preload=True, verbose=False)\n",
    "    # ensure unique channel names\n",
    "    if len(set(raw.ch_names)) != len(raw.ch_names):\n",
    "        mapping = {old: f\"{old}_{i}\" for i, old in enumerate(raw.ch_names)}\n",
    "        raw.rename_channels(mapping)\n",
    "        if verbose: print(\"[loader] made channel names unique\")\n",
    "\n",
    "    # filter/resample\n",
    "    raw.filter(l_freq, h_freq, verbose=False)\n",
    "    if abs(raw.info['sfreq'] - target_sfreq) > 1e-3:\n",
    "        raw.resample(target_sfreq, npad='auto', verbose=False)\n",
    "\n",
    "    picks = mne.pick_types(raw.info, eeg=True, eog=False, exclude='bads')\n",
    "    ch_names = [raw.ch_names[i] for i in picks]\n",
    "    nt = int((tmax - tmin) * target_sfreq)\n",
    "\n",
    "    # collect annotation descriptions and counts\n",
    "    ann = raw.annotations\n",
    "    descs = [str(d) for d in ann.description]\n",
    "    desc_counts = Counter(descs)\n",
    "    if verbose:\n",
    "        print(f\"[loader] {os.path.basename(path)} annotation counts sample:\", list(desc_counts.items())[:12])\n",
    "\n",
    "    # prefer canonical MI markers\n",
    "    preferred = ['769','770','771','772']\n",
    "    if all(p in desc_counts for p in preferred):\n",
    "        mi_descs = preferred\n",
    "        if verbose: print(\"[loader] found canonical MI cues (769-772).\")\n",
    "    else:\n",
    "        # try candidates near 72 counts\n",
    "        exclude_set = set(['32766','768','1023','1072','276','277','783'])\n",
    "        candidates = [d for d,c in desc_counts.items() if (60 <= c <= 80) and (d not in exclude_set)]\n",
    "        if len(candidates) >= 4:\n",
    "            # choose 4 sorted by numeric ID if possible\n",
    "            try:\n",
    "                mi_descs = sorted(candidates, key=lambda s: int(re.search(r'\\d+', s).group()))[:4]\n",
    "            except:\n",
    "                mi_descs = candidates[:4]\n",
    "            if verbose: print(\"[loader] selected MI candidates by counts:\", mi_descs)\n",
    "        else:\n",
    "            # fallback: top-4 frequent non-excluded\n",
    "            sorted_by_count = sorted(desc_counts.items(), key=lambda x: -x[1])\n",
    "            filtered = [d for d,c in sorted_by_count if d not in exclude_set]\n",
    "            if len(filtered) >= 4:\n",
    "                mi_descs = filtered[:4]\n",
    "                if verbose: print(\"[loader] fallback top-4 non-boundary descriptions:\", mi_descs)\n",
    "            else:\n",
    "                # likely no MI cues present (common for E files)\n",
    "                if verbose:\n",
    "                    print(\"[loader] NO 4 MI-related annotations found in\", path)\n",
    "                    print(\"         available descriptions (top):\", sorted_by_count[:12])\n",
    "                return np.zeros((0, len(picks), nt), dtype=np.float32), np.zeros((0,), dtype=int), ch_names\n",
    "\n",
    "    # deterministic mapping\n",
    "    try:\n",
    "        mi_descs_sorted = sorted(mi_descs, key=lambda s: int(re.search(r'\\d+', s).group()))\n",
    "    except:\n",
    "        mi_descs_sorted = sorted(mi_descs)\n",
    "    desc_to_label = {d: i for i,d in enumerate(mi_descs_sorted)}\n",
    "    if verbose:\n",
    "        print(\"[loader] mapping desc->label:\", desc_to_label)\n",
    "        print(\"[loader] chosen counts:\", {d: desc_counts[d] for d in mi_descs_sorted})\n",
    "\n",
    "    # extract epochs aligned to MI cue onsets\n",
    "    Xs, ys = [], []\n",
    "    sfreq = raw.info['sfreq']\n",
    "    for d, onset in zip(descs, ann.onset):\n",
    "        if d in desc_to_label:\n",
    "            sample = int(round(onset * sfreq))\n",
    "            start = sample + int(round(tmin * sfreq))\n",
    "            stop  = sample + int(round(tmax * sfreq))\n",
    "            if start < 0 or stop > raw.n_times:\n",
    "                continue\n",
    "            data = raw.get_data(picks=picks, start=start, stop=stop)\n",
    "            if data.shape[1] != nt:\n",
    "                if data.shape[1] > nt:\n",
    "                    data = data[:, :nt]\n",
    "                else:\n",
    "                    pad = np.zeros((len(picks), nt - data.shape[1]), dtype=np.float32)\n",
    "                    data = np.hstack([data, pad])\n",
    "            Xs.append(data.astype(np.float32))\n",
    "            ys.append(desc_to_label[d])\n",
    "    if len(Xs) == 0:\n",
    "        return np.zeros((0, len(picks), nt), dtype=np.float32), np.zeros((0,), dtype=int), ch_names\n",
    "    X = np.stack(Xs, axis=0)\n",
    "    y = np.array(ys, dtype=int)\n",
    "    if verbose:\n",
    "        print(f\"[loader] extracted epochs shape: {X.shape}, label distribution: {np.bincount(y)}\")\n",
    "    return X, y, ch_names\n",
    "\n",
    "\n",
    "# ------------------ EEG_ARNN model (same structure as earlier) ------------------\n",
    "class TFEMBlock(nn.Module):\n",
    "    def __init__(self, nch, F=16, k_t=15, pool=False, pool_k=4, drop=0.25):\n",
    "        super().__init__()\n",
    "        pad_t = (k_t - 1)//2\n",
    "        self.conv = nn.Conv2d(1, F, kernel_size=(1,k_t), padding=(0,pad_t))\n",
    "        self.bn = nn.BatchNorm2d(F)\n",
    "        self.pw = nn.Conv2d(F, 1, kernel_size=1)\n",
    "        self.pool = nn.AvgPool2d((1,pool_k)) if pool else None\n",
    "        self.elu = nn.ELU()\n",
    "        self.drop = nn.Dropout(drop)\n",
    "    def forward(self,x):\n",
    "        b,nch,t = x.shape\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv(x); x = self.bn(x); x = self.elu(x); x = self.pw(x)\n",
    "        if self.pool: x = self.pool(x)\n",
    "        x = self.drop(x)\n",
    "        return x.squeeze(1)\n",
    "\n",
    "class CARM(nn.Module):\n",
    "    def __init__(self, Wref, tdim, drop=0.25):\n",
    "        super().__init__()\n",
    "        self.Wref = Wref\n",
    "        self.Theta = nn.Parameter(torch.randn(tdim, tdim)*0.01)\n",
    "        self.elu = nn.ELU(); self.drop = nn.Dropout(drop)\n",
    "    def forward(self,x):\n",
    "        h = torch.einsum('ij,bjf->bif', self.Wref, x)\n",
    "        out = torch.einsum('bif,fg->big', h, self.Theta)\n",
    "        out = self.elu(out); out = self.drop(out)\n",
    "        return out\n",
    "\n",
    "class EEG_ARNN(nn.Module):\n",
    "    def __init__(self, nch, T0, ncls=4, F=16, pool_k=4, rho=0.001):\n",
    "        super().__init__()\n",
    "        self.nch=nch; self.T0=T0; self.ncls=ncls; self.rho=rho\n",
    "        W0 = torch.ones(nch,nch) - torch.eye(nch)\n",
    "        Wt = W0 + torch.eye(nch)\n",
    "        D = Wt.sum(dim=1)\n",
    "        Dinv = torch.diag(1.0/torch.sqrt(D + 1e-12))\n",
    "        self.W = nn.Parameter(Dinv @ Wt @ Dinv)\n",
    "        self.tf1 = TFEMBlock(nch, F=F, k_t=15, pool=False)\n",
    "        self.c1  = CARM(self.W, tdim=T0)\n",
    "        self.tf2 = TFEMBlock(nch, F=F, pool=True, pool_k=pool_k)\n",
    "        T2 = T0 // pool_k\n",
    "        self.c2  = CARM(self.W, tdim=T2)\n",
    "        self.tf3 = TFEMBlock(nch, F=F, pool=True, pool_k=pool_k)\n",
    "        T3 = T2 // pool_k\n",
    "        self.c3  = CARM(self.W, tdim=T3)\n",
    "        self.fuse = nn.Conv2d(1,16,kernel_size=(nch,1))\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.elu = nn.ELU()\n",
    "        self.fc = nn.Linear(16*T3, ncls)\n",
    "    def forward(self,x):\n",
    "        x = self.tf1(x); x = self.c1(x)\n",
    "        x = self.tf2(x); x = self.c2(x)\n",
    "        x = self.tf3(x); x = self.c3(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.fuse(x); x = self.bn(x); x = self.elu(x); x = self.drop(x)\n",
    "        x = x.squeeze(2)\n",
    "        b,oc,t = x.shape\n",
    "        x = x.view(b, oc*t)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# ------------------ Helpers: normalization, train/eval ------------------\n",
    "def zscore_epochs(X):\n",
    "    Xz = X.copy()\n",
    "    n, ch, t = Xz.shape\n",
    "    for i in range(n):\n",
    "        mu = Xz[i].mean(axis=1, keepdims=True)\n",
    "        sd = Xz[i].std(axis=1, keepdims=True) + 1e-12\n",
    "        Xz[i] = (Xz[i] - mu) / sd\n",
    "    return Xz\n",
    "\n",
    "def train_epoch(model, loader, opt, crit, device):\n",
    "    model.train(); total=0; n=0\n",
    "    for xb,yb in loader:\n",
    "        xb,yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad()\n",
    "        out = model(xb); loss = crit(out,yb)\n",
    "        loss.backward(); opt.step()\n",
    "        # manual update for W (paper-like)\n",
    "        with torch.no_grad():\n",
    "            if model.W.grad is not None:\n",
    "                model.W.data = (1.0 - model.rho) * model.W.data - model.rho * model.W.grad.data\n",
    "                model.W.grad.zero_()\n",
    "        total += loss.item() * xb.size(0); n += xb.size(0)\n",
    "    return total / max(1,n)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    preds=[]; ys=[]\n",
    "    for xb,yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        out = model(xb)\n",
    "        preds.append(out.argmax(dim=1).cpu().numpy())\n",
    "        ys.append(yb.numpy())\n",
    "    if len(preds)==0:\n",
    "        return np.array([]), np.array([])\n",
    "    return np.concatenate(preds), np.concatenate(ys)\n",
    "\n",
    "\n",
    "# ------------------ Per-subject CV evaluation ------------------\n",
    "subjects = [f\"A0{i}\" for i in range(1,10)]\n",
    "subject_results = {}\n",
    "\n",
    "for subj in subjects:\n",
    "    print(\"\\n========================\", subj, \"========================\")\n",
    "    tpath = os.path.join(DATA_ROOT, subj + \"T.gdf\")\n",
    "    epath = os.path.join(DATA_ROOT, subj + \"E.gdf\")\n",
    "    # load train (robust)\n",
    "    Xtr, ytr, chs = load_bci_gdf_robust(tpath, verbose=True)\n",
    "    if Xtr.size == 0:\n",
    "        print(f\"[{subj}] No train epochs found, skipping subject.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"[{subj}] train epochs shape: {Xtr.shape}, classes: {np.bincount(ytr)}\")\n",
    "    # check if eval file contains MI cues (if yes, we could evaluate directly)\n",
    "    Xte, yte, _ = load_bci_gdf_robust(epath, verbose=False)\n",
    "    if Xte.size > 0:\n",
    "        print(f\"[{subj}] NOTE: evaluation file contains MI cues (will evaluate after CV).\")\n",
    "    else:\n",
    "        print(f\"[{subj}] NOTE: evaluation file does NOT contain MI cues (we will use stratified CV on training only).\")\n",
    "\n",
    "    # normalize\n",
    "    Xtr = zscore_epochs(Xtr)\n",
    "\n",
    "    # CV splits\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    fold_best = []\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(Xtr, ytr), 1):\n",
    "        X_trf, y_trf = Xtr[tr_idx], ytr[tr_idx]\n",
    "        X_valf, y_valf = Xtr[val_idx], ytr[val_idx]\n",
    "\n",
    "        tr_loader = DataLoader(TensorDataset(torch.tensor(X_trf), torch.tensor(y_trf)), batch_size=BATCH, shuffle=True, drop_last=False)\n",
    "        val_loader = DataLoader(TensorDataset(torch.tensor(X_valf), torch.tensor(y_valf)), batch_size=BATCH, shuffle=False)\n",
    "\n",
    "        model = EEG_ARNN(nch=Xtr.shape[1], T0=Xtr.shape[2], ncls=len(np.unique(ytr))).to(device)\n",
    "        params = [p for n,p in model.named_parameters() if n!='W' and p.requires_grad]\n",
    "        opt = torch.optim.AdamW(params, lr=LR, weight_decay=1e-4)\n",
    "        crit = nn.CrossEntropyLoss()\n",
    "\n",
    "        best_val_acc = 0.0\n",
    "        best_epoch = 0\n",
    "        wait = 0\n",
    "        for ep in range(1, EPOCHS+1):\n",
    "            tloss = train_epoch(model, tr_loader, opt, crit, device)\n",
    "            preds_val, yv = evaluate(model, val_loader, device)\n",
    "            if preds_val.size>0:\n",
    "                vacc = accuracy_score(yv, preds_val)\n",
    "            else:\n",
    "                vacc = 0.0\n",
    "            if vacc > best_val_acc:\n",
    "                best_val_acc = vacc\n",
    "                best_epoch = ep\n",
    "                wait = 0\n",
    "                # you can save fold model here if desired\n",
    "            else:\n",
    "                wait += 1\n",
    "            if ep % 10 == 0 or ep == 1:\n",
    "                print(f\"[{subj}] fold {fold} ep {ep:03d} train_loss={tloss:.4f} val_acc={vacc:.4f}\")\n",
    "            if wait >= PATIENCE:\n",
    "                print(f\"[{subj}] fold {fold} early stopping at ep {ep}, best_val={best_val_acc:.4f} (epoch {best_epoch})\")\n",
    "                break\n",
    "        fold_best.append(best_val_acc)\n",
    "        print(f\"[{subj}] fold {fold} best_val_acc = {best_val_acc:.4f}\")\n",
    "\n",
    "    mean_acc = float(np.mean(fold_best))\n",
    "    std_acc  = float(np.std(fold_best))\n",
    "    subject_results[subj] = {'folds': fold_best, 'mean': mean_acc, 'std': std_acc, 'n_trials': Xtr.shape[0]}\n",
    "\n",
    "    print(f\"[{subj}] CV mean ± std = {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "\n",
    "# ------------------ Summary print ------------------\n",
    "print(\"\\n\\n====== SUBJECT-WISE SUMMARY ======\")\n",
    "subjects_done = sorted(subject_results.keys())\n",
    "means = []\n",
    "for s in subjects_done:\n",
    "    m = subject_results[s]['mean']; sd = subject_results[s]['std']\n",
    "    n = subject_results[s]['n_trials']\n",
    "    means.append(m)\n",
    "    print(f\"{s}: mean acc = {m*100:.2f}%, std = {sd*100:.2f}%, trials={n}\")\n",
    "if len(means)>0:\n",
    "    print(f\"\\nOverall mean (subjects) = {np.mean(means)*100:.2f}% ± {np.std(means)*100:.2f}%\")\n",
    "\n",
    "# ------------------ Bar plot (per-subject mean) ------------------\n",
    "if len(means) > 0:\n",
    "    plt.figure(figsize=(9,4))\n",
    "    plt.bar(subjects_done, [subject_results[s]['mean']*100 for s in subjects_done])\n",
    "    plt.axhline(np.mean([subject_results[s]['mean']*100 for s in subjects_done]), linestyle='--')\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(\"Subject-wise CV mean accuracy (per-subject 5-fold CV on training sessions)\")\n",
    "    plt.show()\n",
    "\n",
    "# ------------------ Note on evaluation files ------------------\n",
    "print(\"\\nNote: many AxxE.gdf files in your folder do not contain MI cue annotations (769..772).\")\n",
    "print(\"      That's why we used stratified CV on each subject's training session (AxxT.gdf).\")\n",
    "print(\"If you have separate ground-truth label files for evaluation sessions, tell me their filenames and I'll show how to combine them.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaf1307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
